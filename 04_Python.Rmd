
```{r, include=FALSE, echo=FALSE}
require(knitr)
knitr::opts_chunk$set(eval=FALSE, results=TRUE, message=FALSE, warning=FALSE, error=FALSE, 
                      fig.path="figures/")
#knitr::opts_knit$set(root.dir="Python/PythonInstall")
require(reticulate)
use_condaenv(condaenv="r-reticulate", required=TRUE)
```

# Python 

## Simple linear regression

### Setup

First, let's import the libraries used for simulation based power analysis in Python.

```{python}
import random
import numpy as np
import pandas as pd

from sklearn.linear_model import LinearRegression
import statsmodels.api as sm
import scipy

import matplotlib.pyplot as plt
```

Set the seed to 1024.

```{python}
np.random.seed(1024)
```

### Step 1: model specification

Write down the regression model, including all variables and parameters of interest:

$$
bpsystol = \beta_0 + \beta_1(age) + \beta_2(sex) + \beta_3(age*sex) + \epsilon
$$

where the variables of interest are age, sex and the interaction of age and sex. Also, you need to estimate the coefficients for $\beta_0$, $\beta_1$, $\beta_2$, $\beta_3$.

### Step 2: Variable composition

Specify the details of the covariates, such as the range of age or the proportion of females.

### Step 3: Parameter composition

Locate or think about reasonable values for the parameters in your model.

### Step 4: Simulate

Next, we create a simulated dataset based on our assumptions about the model under the alternative hypothesis, and fit the model.

```{python}
def generate_dataset(sample_size, interact_coef):
    
    data_set = []
    
    for i in range(sample_size):
        
        _id = i
        age = np.random.randint(18,66)
        female = np.random.choice([0, 1])
        interact = age * female
        e = np.random.normal(0, 20)
        
        sbp = 110 + 0.5*age + (-20)*female + interact_coef*interact + e
        
        data_set.append([_id, age, female, interact, e, sbp])
      
    data_set = pd.DataFrame(data_set)
    data_set.columns = ["_id", "age", "female", "interact", 'e', "sbp"]
    
    return data_set
```

### Step 5: Automate

Next, let's write a function that creates datasets under the alternative hypothesis, fits the models, and uses a likelihood-ratio test to calculate power.

```{python}
def cal_power(sample_size, interact_coef, simiu_cnt, alpha):
    
    power_list = []
    
    for i in range(simiu_cnt):
        
        dataset = generate_dataset(sample_size, interact_coef)
    
        y1 = dataset['sbp']
        x1 = dataset[['age', 'female', 'interact']]
        x1 = sm.add_constant(x1)
        full_model = sm.OLS(y1, x1).fit()
        full_ll = full_model.llf
    
        y2 = dataset['sbp']
        x2 = dataset[['age', 'female']]
        x2 = sm.add_constant(x2)
        reduced_model = sm.OLS(y2, x2).fit()
        reduced_ll = reduced_model.llf
    
        LR_statistic = -2*(reduced_ll-full_ll)
        power = scipy.stats.chi2.sf(LR_statistic, 1)
        
        if power<=alpha:
            power_list.append(1)
        else:
            power_list.append(0)
    
    mean_power = sum(power_list)/len(power_list)
    
    return [sample_size, interact_coef, mean_power]
```

```{python}
result = []

for i in range(400, 800, 100):
    for j in [0.2, 0.25, 0.3, 0.35, 0.4]:
        result.append(cal_power(sample_size = i, interact_coef = j, simiu_cnt = 1000, alpha = 0.05))

result = pd.DataFrame(result)
result.columns = ['N', 'interact_coef', 'Power']
result
```

### Step 6: Summarize & visualize

In this part, we export the results of the simulations which include two parts: a table and a graph showing the results from the simulations. It should be noted that the graph from Python simulation is a little bit different from that in Stata, and this is mainly caused by different simulation process within Stata and Python. 

```{python}
	N	interact_coef	Power
0	400	0.20	0.320
1	400	0.25	0.413
2	400	0.30	0.557
3	400	0.35	0.664
4	400	0.40	0.798
5	500	0.20	0.328
6	500	0.25	0.513
7	500	0.30	0.636
8	500	0.35	0.788
9	500	0.40	0.869
10	600	0.20	0.406
11	600	0.25	0.569
12	600	0.30	0.714
13	600	0.35	0.829
14	600	0.40	0.926
15	700	0.20	0.447
16	700	0.25	0.601
17	700	0.30	0.776
18	700	0.35	0.887
19	700	0.40	0.955
```

```{python}
n_list = result['N'].unique()
color_list = ['darkblue', 'firebrick', 'darkgreen', 'orange']

plt.figure(figsize=(15,6))

for i in range(len(n_list)):
    n = n_list[i]
    c = color_list[i]
    plt.plot(result[result['N']==n]['interact_coef'], result[result['N']==n]['Power'], 'o-', color = c)

plt.grid()

plt.xticks([0.2, 0.25, 0.3, 0.35, 0.4], fontsize = 12)
plt.yticks([0.2, 0.4, 0.6, 0.8, 1], fontsize = 12)

plt.xlabel('interact', fontsize = 15)
plt.ylabel('Power', fontsize = 15)  

plt.legend(result['N'].unique(), fontsize = 12)
plt.title('Estimate Power: Two-sided Test', fontsize = 18)

plt.show()
```

![](https://github.com/hlmshtj-dan/pigo/blob/main/7.png?raw=true)


## Mixed effects model

### Setup

We import the same libraries as previously.

```{python}
import random
import numpy as np
import pandas as pd

from sklearn.linear_model import LinearRegression
import statsmodels.api as sm
import scipy

import matplotlib.pyplot as plt
```
Again, we set seed to 1024.

```{python}
np.random.seed(1024)
```

### Step 1: model specification

Write down the regression model, including all variables and parameters of interest:

$$
weight_{it} = \beta_0 + \beta_1(age_{it}) + \beta_2(female_i) + \beta_3(age_{it}*female_i) + \mu_{0i} + \mu_{1i}(age) + \epsilon_{it}
$$

where $i$ stands for `children`, $t$ for `age`, and we assume $\mu_{0i} \sim N(0, \tau_0)$, $\mu_{1i}\sim N(0, \tau_1)$, $\epsilon_{it} \sim N(0, \sigma)$.

The covariates are `weight`, `age`, `female`, and the interaction term `age\*female`. Also, we need to estimate the coefficients for $\beta_0$ (Intercept), $\beta_1$ (coefficient for age), $\beta_2$ (coefficient for the female comparing with the male), $\beta_3$ (coefficient for the interaction), $\mu_{1i}$ (random effect of age).

We also need to think about the covariates in our model. This is a longitudinal study, so we need to specify the starting age, the length of time between measurements, and the total number of measurements. We also need to consider the proportion of males and females in our study. Are we likely to sample 50% females and 50% males?

Let's assume that we will measure the childrens' weight every 6 months for 2 years beginning at age 12. And let's also assume that the sample will be 50% female. The interaction term ageÃ—female is easy to calculate once we create variables for age and female.

### Step 2: Variable composition

Specify the details of the covariates, such as the range of age or the proportion of females.

Let's assume that we will measure the children's weight every 4 months for 4 years beginning at age 10. Also, in the sample, the proportion of female is equal to that of male. It's not difficult to calculate the iteration term when generate the variable for age and female.

### Step 3: Parameter composition

Locate or think about reasonable values for the parameters in your model. In this step, we use an external data set measuring Asian kid's data to estimate the coefficients for the above regression model, and we get $\beta_0=5.35$, $\beta_1=3.59$, $\beta_2=-0.47$, $\beta_3=-0.24$, $\tau_0=0.24$, $\tau_1=-0.57$ and $\sigma=1.17$.

```{python}
# missing code here
```

### Step 4: Simulate

Next, we create a simulated dataset based on our assumptions about the model under the alternative hypothesis, and fit the model. We will simulate 5 observations at 4-month increments for 200 children.

```{python}
def generate_dataset(sample_size, obser_cnt):
    
    data_set = []
    
    for i in range(sample_size):
        child_id = i
        female_origin = np.random.choice([0, 1])
        u_0i_origin = np.random.normal(0, 0.25)
        u_1i_origin = np.random.normal(0, 0.60)
        
        for j in range(obser_cnt):
            
            child = child_id
            female = female_origin
            age = 0.5*j
            u_0i = u_0i_origin
            u_1i = u_1i_origin
            interaction = age * female
            e_ij = np.random.normal(0, 1.2)
            weight = 5.35 + 3.6*age + (-0.5)*female + (-0.25)*interaction + u_0i + age*u_1i + e_ij
            
            data_set.append([child, female, age, u_0i, u_1i, interaction, e_ij, weight])
      
    data_set = pd.DataFrame(data_set)
    data_set.columns = ["child_id", "female", "age", "u_0i", "u_li", "interaction", "e_ij", "weight"]
    
    return data_set
```

### Step 5: Automate

Next, let's write a function that creates datasets under the alternative hypothesis, fits the mixed effects models, tests the null hypothesis of interest, and uses a for loop to run many iterations of the function.

```{python}
def cal_power(sample_size, obser_cnt, simiu_cnt, alpha):
    
    power_list = []
    
    for i in range(simiu_cnt):
        
        dataset = generate_dataset(sample_size, obser_cnt)
    
        y1 = dataset['weight']
        x1 = dataset[['female', 'age', 'interaction']]
        x1 = sm.add_constant(x1)
        full_model = sm.OLS(y1, x1).fit()
        full_ll = full_model.llf
    
        y2 = dataset['weight']
        x2 = dataset[['female', 'age']]
        x2 = sm.add_constant(x2)
        reduced_model = sm.OLS(y2, x2).fit()
        reduced_ll = reduced_model.llf
    
        LR_statistic = -2*(reduced_ll-full_ll)
        power = scipy.stats.chi2.sf(LR_statistic, 1)
        
        if power<=alpha:
            power_list.append(1)
        else:
            power_list.append(0)
    
    mean_power = sum(power_list)/len(power_list)
    
    return [obser_cnt, sample_size, mean_power]
```

```{python}
result = []

for i in range(100, 600, 100):
    for j in range(5, 7):
        result.append(cal_power(sample_size = i, obser_cnt = j, simiu_cnt = 1000, alpha = 0.05))

result = pd.DataFrame(result)
result.columns = ['n1', 'N', 'Power']
result
```

### Step 6: Summarize & visualize

The last procedure is to export the results which contain a table and a graph. 

```{python}
n1	N	Power
0	5	100	0.290
1	6	100	0.398
2	5	200	0.491
3	6	200	0.632
4	5	300	0.655
5	6	300	0.798
6	5	400	0.779
7	6	400	0.917
8	5	500	0.857
9	6	500	0.940
```

```{python}
n1_list = result['n1'].unique()
color_list = ['darkblue', 'firebrick']

plt.figure(figsize=(15,6))

for i in range(len(n1_list)):
    n = n1_list[i]
    c = color_list[i]
    plt.plot(result[result['n1']==n]['N'], result[result['n1']==n]['Power'], '-o', color = c)

plt.grid()

plt.xticks([100, 200, 300, 400, 500], fontsize = 12)
plt.yticks([0.2, 0.4, 0.6, 0.8, 1], fontsize = 12)

plt.xlabel('Level 2 Sample Size', fontsize = 15)
plt.ylabel('Power', fontsize = 15)  

plt.legend(result['n1'].unique(), fontsize = 12)
plt.title('Power: Two-sided Test', fontsize = 18)

plt.show()
```

![](https://github.com/hlmshtj-dan/pigo/blob/main/8.png?raw=true)
