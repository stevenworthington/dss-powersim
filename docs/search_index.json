[["index.html", "Simulation-Based Power Analysis Table of Contents Contributors", " Simulation-Based Power Analysis This tutorial is designed to be a quick-start guide for conducting simulation-based power analyses in R, Python, and Stata. We focus particularly on power for mixed effects models, but the principles employed can be repurposed for any model and study design. The tutorial is suitable for anyone with a intermediate understanding of mixed effects models and coding in either R, Python, or Stata. While high-level packages exist in some of these languages for conducting simulation-based power analysis (e.g., the R packages {simr}, {longpower}, and {simglm}), such packages abstract away the details of conducting simulations and thus are best used after gaining an understanding of the power simulation process. In addition, rolling your own simulations from scratch provides much more flexibility to tackle different study designs and models - and it’s fun! We are always grateful for any feedback you are willing to provide about our tutorials! Please email help@iq.harvard.edu with any thoughts. Table of Contents Canned Power Analysis Simulation-based Power Analysis Power of What? R Examples Python Examples Stata Examples Software Comparison Resources   Contributors The contents of these workshops are the result of a collaborative effort from members of the Data Science Services team at the Institute for Quantitative Social Science at Harvard University. The main contributors are Steve Worthington and Dan Yuan, with additional feedback from Jinjie Liu and Noah Greifer. "],["power-analysis.html", "1 Power Analysis 1.1 Canned routines 1.2 Step by step", " 1 Power Analysis Statistical power is the probability of rejecting a null hypothesis when it is false, or equivalently, of detecting an effect if such an effect exists. 1.1 Canned routines For some studies, it can be an important step to calculate a priori statistical power. We use statistical power to determine the probability of rejecting a null hypothesis when it is false, or equivalently, of detecting an effect if such an effect exists. \\[ \\begin{align} \\textrm{Power} &amp;= \\textrm{Pr}(\\textrm{reject} \\, H_0 \\, | \\, H_0 \\, \\textrm{is false}) \\\\ &amp;= 1 - \\textrm{Pr}(\\textrm{fail to reject} \\, H_0 \\, | \\, H_0 \\, \\textrm{is false}) \\\\ &amp;= 1 - \\beta \\end{align} \\] We want \\(\\beta\\) (Type II error) to be small and power to be large. When designing a study, rather than calculating power when sample size and effect size are fixed, researchers typically want to know the sample size required to reject a null hypothesis at a given level of power and effect size. In some situations, where the study design and/or model of interest is fairly simple, we can use a formula to calculate the sample size required to reject a null hypothesis. We will use a simple example to show the process involved. For instance, if we plan to perform a test of an hypothesis comparing the cholesterol levels of people in two populations, one with a diet comprising low oat consumption and the other with high oat consumption, we could specify the following null and alternative hypotheses, respectively: \\[ \\begin{align} \\textrm{H}_0 : \\mu_1 - \\mu_2 &amp;= 0 \\\\ \\textrm{H}_1 : \\mu_1 - \\mu_2 &amp;\\neq 0 \\end{align} \\] where \\(\\mu_1\\) and \\(\\mu_2\\) are the mean cholesterol levels in the two populations being compared. We can use a formula to determine the sample sizes required so that the test has a specific power. We will need the following inputs to the formula: \\(\\alpha\\) (Type I error / significance level): typically, this is set to \\(0.05\\) in most studies. \\(1 - \\beta\\) (power): often this is set to \\(0.8\\) or \\(0.9\\). \\(\\sigma\\) (population standard deviation): we need to estimate/guess this. \\(\\delta\\) (alternative hypothesis): ideally the smallest difference \\(\\delta = \\mu_1 - \\mu_2\\) that has scientific or clinical importance. Given \\(\\alpha\\), \\((1 - \\beta)\\), \\(\\sigma\\), and \\(\\delta\\), we can calculate \\(n_g\\) the sample size in each group to reject \\(\\textrm{H}_0\\) with probability \\((1 - \\beta)\\). To simplify things a little, we will use the normal distribution as an approximation to the \\(t\\) distribution (which should be fine when \\(n_g \\geq 30\\)). Here is the formula for this approximate two-sample \\(t\\)-test: \\[ n_g \\approx 2(z_{\\alpha / 2} + z_\\beta)^2 \\left( \\frac{\\sigma}{\\delta} \\right)^2 \\] where \\(n_g\\) is the sample size required in each group, \\(z_{\\alpha/2}\\) is the value from the standard normal distribution holding half the selected \\(\\alpha\\) level below it (because this is a two-tailed test), \\(z_\\beta\\) is the value from the standard normal distribution holding the \\(\\beta\\) level below it, \\(\\delta\\) is the effect size (the difference in population averages \\(\\mu_1 - \\mu_2\\) of cholesterol), and \\(\\sigma\\) is the pooled population standard deviation (during study planning we usually assume equal variances in the two groups). Typically, we would set \\(\\alpha\\) and \\(\\beta\\) to the following values and rely on previous studies or pilot data to obtain reasonable values for \\(\\sigma\\) and \\(\\delta\\): \\(\\alpha = 0.05\\), so \\(z_{\\alpha / 2} = 1.960\\). \\(1 - \\beta = 0.8\\), so \\(\\beta = 0.2\\), so \\(z_\\beta = 0.8416\\). \\(\\sigma = 1\\); this could be our best guess based on previous studies. \\(\\delta = 0.7\\), our best guess based on previous studies could be that mean differences of 0.7 mmol/L or greater should be considered biologically important. We can then plug these input values into our formula: \\[ n_g \\approx 2(1.960 + 0.8416)^2 \\left( \\frac{1}{0.7} \\right)^2 = 32.036 \\] We always round up to a whole number for sample size, so for this study we need 33 subjects per group, or \\(n=66\\) in total. In practice, we will often rely on software to perform the above calculation for us. In R we can use the power.t.test() function from the built-in {stats} package to calculate the sample size needed to reject the null hypothesis that \\(\\textrm{H}_0 : \\mu_1 - \\mu_2 = 0\\). We just need to pass the \\(n\\) parameter as NULL to tell R that we’d like to calculate sample size based on the values of the other parameters: power.t.test(n=NULL, delta=0.7, sd=1, sig.level=0.05, power=0.8, alternative=&quot;two.sided&quot;) ## ## Two-sample t test power calculation ## ## n = 33.02467 ## delta = 0.7 ## sd = 1 ## sig.level = 0.05 ## power = 0.8 ## alternative = two.sided ## ## NOTE: n is number in *each* group 1.2 Step by step Here are the general set of steps required to implement a power analysis for most study designs: 1. Specify a hypothesis test. Make explicit a null and alternative hypothesis. 2. Specify Type I and Type II error levels for the test. Typically, the Type I error level (significance level / false positive level) is set to \\(\\alpha=0.05\\) and Type II error level (false negative level) \\(\\beta=0.2\\), which yields a power level of \\(1 - \\beta = 0.8\\), but other values could be substituted instead. 3. Specify the estimated effect size level for the test. To solve for sample size \\(n\\), we need an estimate of effect size (\\(\\delta = \\mu_1 - \\mu_2\\)) that has scientific meaning. Sometimes we need to use a pilot dataset or look to previous studies to get this value. 4. Calculate the sample size required to obtain the power level desired. This can either be done by pugging and chugging values into the relevant formula, or by using a software-based implementation of said formula. "],["simulation.html", "2 Simulation 2.1 Customization 2.2 Step by step", " 2 Simulation 2.1 Customization Formulas often do not exist to calculate power for the effect of interest and therefore canned functions/programs/macros may not be available. For some studies, such as those involving complex study designs or those using mixed effects models for inference, we must therefore rely on simulation to provide a means of generating estimates of power that are customized for our current situation. The basic idea is to simulate running our study many times and calculate the proportion of times we reject the null hypothesis. This proportion provides an estimate of power. Generating a dataset and running an analysis for the hypothesis test is part of the simulation. Randomness is introduced into the process during dataset generation. For example, say the desired power level is 90%, and you want to calculate the sample size required to obtain this level of power. We could use the “guess sample size and check power” method. Firstly, choose a sample size \\(n_1\\) and run the simulation to estimate power. If power is estimated to be lower than 90%, select a new value \\(n_2\\) that is larger than \\(n_1\\) and run the simulation again. Simulation runs are repeated until the estimated power is roughly 90%. 2.2 Step by step There are two broad steps involved in conducting simulation-based power analysis: 1) thinking and, 2) implementing. Think Model specification: Write down the regression model, including all variables and parameters of interest. Variable composition: Specify the form of the explanatory variables, such as the range of age or BMI, proportion of females/males, or the coding scheme used for categorical terms. Parameter composition: Establish reasonable values for the data-generating parameters in your model. Implement Simulate: Simulate the sampling process for a single dataset, assuming the alternative hypothesis, and fit the model of interest. Automate: Write a function/program/macro to automate the process of creating datasets, fitting models, testing the hypothesis of interest, and calculating power. The function/program/macro should be flexible enough to allow for iterating power calculations over a grid of different parameter values. Summarize: Summarize the relationships between power, sample size, and effect size in tables and figures. "],["power-of-what.html", "3 Power of What? 3.1 Study design 3.2 Mixed effects model", " 3 Power of What? The initial steps of power simulation involve nothing more than thinking and writing down your thoughts using a pencil and paper. But, prior to walking through these steps, there is an even more fundamental issue to be addressed - the power of what? What quantity within your model do you wish to calculate power for? Overall model goodness-of-fit, individual parameters, or combinations of parameters? The point of entry for power analysis is always to identify the particular effect of interest, and for that you must answer the question: “power of what?” 3.1 Study design The study design we will use as an example throughout this tutorial comes from Julian Quandt’s blogpost (https://julianquandt.com/post/power-analysis-by-data-simulation-in-r-part-iv/). He describes this as: A new hypothetical research question focused on music preference. The overarching research goal will be to find out whether Rock or Pop music is better. Of course, we could just ask people what they prefer, but we want a more objective measure of what is Rock and Pop (people might have different ideas about the genres). Therefore, we will have participants listen to a bunch of different songs that are either from a Spotify “best-of-pop” or “best-of-rock” playlist and have them rate each song on an evaluation scale from 0-100 points. 3.2 Mixed effects model Canned routines exist to perform power analysis for some simple general linear models (GLMs), however, for generalized linear mixed effects models (GLMMs) we must rely on simulation. We will walk through the process of calculating power for a GLMM in a step by step manner, which will serve as scaffolding to build intuition about the process of conducting power simulation more generally. Once we have the workflow down, we can automate the simulation process using functions. While the outcome in this example is bounded on the interval [0, 100], we will not concern ourselves with the issue of using a linear model with such an outcome. 3.2.1 Step 1: model specification The first step in simulation-based power analysis is to write down the regression model of interest, including all variables and parameters: \\[ \\textrm{liking}_{ij} = \\beta_0 + b_{0j} + (\\beta_1 + b_{1j}) \\times \\textrm{genre}_i + \\epsilon_{ij} \\] where the subscripts \\(i\\) and \\(j\\) denote individual songs and participants, respectively, liking is an integer-based rating of a given song on the interval [0, 100], genre is a dummy coded binary variable indicating whether the song is classified as “rock” or “pop”, and we assume \\(b_{0j} \\sim \\mathcal{N}(0, \\tau_0)\\), \\(b_{1j} \\sim \\mathcal{N}(0, \\tau_1)\\), \\(\\epsilon_{ij} \\sim \\mathcal{N}(0, \\sigma)\\). The parameter of interest is \\(\\beta_1\\) - the average (within-subject) difference in the rating of songs between the two genres. Table 3.1 lists all of the variables and parameters in the model. Table 3.1: Variables in the data-generating model and associated code-based names. model code description \\(\\textrm{liking}_{ij}\\) \\(\\texttt{liking_ij}\\) rating of song \\(i\\) for participant \\(j\\) on the interval [0, 100] \\(\\textrm{genre}_i\\) \\(\\texttt{genre_i}\\) genre of song \\(i\\) (0=‘pop’, 1=‘rock’) \\(\\beta_0\\) \\(\\texttt{beta_0}\\) intercept; mean of liking rating for ‘pop’ genre \\(\\beta_1\\) \\(\\texttt{beta_1}\\) slope; mean difference btw ‘pop’ and ‘rock’ song ratings \\(\\tau_0\\) \\(\\texttt{tau_0}\\) standard deviation of by-subject random intercepts \\(\\tau_1\\) \\(\\texttt{tau_1}\\) standard deviation of by-subject random slopes \\(\\rho\\) \\(\\texttt{rho}\\) correlation between by-subject random intercepts and slopes \\(\\sigma\\) \\(\\texttt{sigma}\\) standard deviation of residuals \\(b_{0j}\\) \\(\\texttt{b_0j}\\) random intercept for subject \\(j\\) \\(b_{1j}\\) \\(\\texttt{b_1j}\\) random slope for subject \\(j\\) \\(e_{ij}\\) \\(\\texttt{e_ij}\\) residual of song \\(i\\) for participant \\(j\\) 3.2.2 Step 2: Variable composition Once we have the model equation, we need to specify the details of the explanatory variables. In our model, we only have a single binary predictor, so the only decision to make is which coding scheme to use: dummy coding, zero sum coding, or something else. Here, we chose dummy coding, since our primary interest is in the difference between the “rock” and “pop” genres. In many other situations, we might include variables such as age and sex in the model. In which case we would need to determine reasonable settings for the range of age and the proportion of females to males. For example, the range of age might encompass the full possible range of human longevity (e.g., 0 to 120 years) or could be more focused on non-retired adults (e.g., 18 to 65 years). The proportion of females to males could theoretically vary anywhere in the interval (0, 1), but practically is rarely outside of the interval [0.45, 0.55]. 3.2.3 Step 3: Parameter composition Finally, we need to establish the data-generating parameters in the model. You may draw on your own, or your colleague’s, substantive expertise about the phenomenom you’re studying to determine what paramater values are plausible. Or, you might look to the literature for studies that examined similar effects. Table 3.2 lists parameter values we will use as a starting point. Later, we will try alternative values and compare power for each. Table 3.2: Settings for all data-generating parameters. code value description \\(\\texttt{beta_0}\\) 65 intercept; i.e., mean of liking rating for ‘pop’ genre \\(\\texttt{beta_1}\\) 15 slope; i.e, mean difference btw ‘pop’ and ‘rock’ song ratings \\(\\texttt{tau_0}\\) 7 by-subject random intercept sd \\(\\texttt{tau_1}\\) 3 by-subject random slope sd \\(\\texttt{rho}\\) 0.2 correlation between intercept and slope \\(\\texttt{sigma}\\) 5 residual (error) sd "],["r.html", "4 R 4.1 Setup 4.2 Data simulation step by step 4.3 Data simulation automated 4.4 Power calculation (single run) 4.5 Power calculation automated 4.6 Power for different effect sizes", " 4 R 4.1 Setup The main library we will use is stats and comes bundled with base R. However, we also need to install a few additional libraries onto our machine and then load them into our search path. # uncomment the line below to install the {pacman} library on your computer # install.packages(&quot;pacman&quot;) pacman::p_load( lme4, # model specification / estimation lmerTest, # provides p-values in the model output future, # parallelization future.apply, # fast automation furrr, # fast functional programming faux, # simulate from multivariate normal distribution broom.mixed, # extracting tidy data from model fits tidyverse, # data wrangling and visualisation gt # nice tables ) We will also set the pseudo-random number generator seed to 02138 to make the stochastic components of our simulations reproducible. set.seed(02138) Finally, let’s take advantage of background parallelization to speed-up R processes. plan(multisession) 4.2 Data simulation step by step Let’s write some code that creates datasets under the alternative hypothesis. 4.2.1 Establish the data-generating parameters # set all data-generating parameters beta_0 &lt;- 65 # intercept; i.e., the grand mean beta_1 &lt;- 15 # slope; i.e, effect of category tau_0 &lt;- 7 # by-subject random intercept sd tau_1 &lt;- 4 # by-subject random slope sd rho &lt;- 0.2 # correlation between intercept and slope sigma &lt;- 8 # residual (error) sd 4.2.2 Simulate the sampling process # set number of subjects and items n_subj &lt;- 100 # number of subjects n_pop &lt;- 25 # number of songs in pop category n_rock &lt;- 25 # number of songs in rock category 4.2.3 Simulate the sampling of songs # simulate a sample of songs songs &lt;- tibble( song_id = seq_len(n_pop + n_rock), category = rep(c(&quot;pop&quot;, &quot;rock&quot;), c(n_pop, n_rock)), genre_i = rep(c(0, 1), c(n_pop, n_rock)) ) 4.2.4 Simulate the sampling of subjects We will use the function faux::rnorm_multi(), which generates a table of n simulated values from a multivariate normal distribution by specifying the means (mu) and standard deviations (sd) of each variable, plus the correlations (r), which can be either a single value (applied to all pairs), a correlation matrix, or a vector of the values in the upper right triangle of the correlation matrix. # simulate a sample of subjects # sample from a multivariate normal distribution subjects &lt;- faux::rnorm_multi( n = n_subj, mu = 0, # means for random effects are always 0 sd = c(tau_0, tau_1), # set SDs r = rho, # set correlation, see ?rnorm_multi varnames = c(&quot;b_0j&quot;, &quot;b_1j&quot;) ) |&gt; mutate(subj_id = seq_len(n_subj)) # add subject IDs 4.2.5 Check the simulated values tibble( parameter = c(&quot;tau_0&quot;, &quot;tau_1&quot;, &quot;rho&quot;), value = c(tau_0, tau_1, rho), simulated = c( sd(subjects$b_0j), sd(subjects$b_1j), cor(subjects$b_0j, subjects$b_1j) ) ) ## # A tibble: 3 × 3 ## parameter value simulated ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 tau_0 7 7.05 ## 2 tau_1 4 3.90 ## 3 rho 0.2 0.119 4.2.6 Simulate trials # cross subject and song IDs; add an error term trials &lt;- crossing(subjects, songs) |&gt; mutate(e_ij = rnorm(n(), mean = 0, sd = sigma)) 4.2.7 Calculate response values dat_sim &lt;- trials |&gt; mutate(liking_ij = beta_0 + b_0j + (beta_1 + b_1j) * genre_i + e_ij) %&gt;% select(subj_id, category, genre_i, liking_ij) 4.2.8 Plot the data dat_sim |&gt; ggplot(aes(category, liking_ij, color = category)) + # predicted means geom_hline(yintercept = (beta_0 + 0*beta_1), color = &quot;orange&quot;, linetype = &quot;dashed&quot;, linewidth = 1) + geom_hline(yintercept = (beta_0 + 1*beta_1), color = &quot;dodgerblue&quot;, linetype = &quot;dashed&quot;, linewidth = 1) + # actual data geom_violin(alpha = 0.5, show.legend = FALSE, fill = &quot;grey65&quot;) + stat_summary(fun = mean, geom=&quot;crossbar&quot;, show.legend = FALSE) + scale_color_manual(values = c(&quot;orange&quot;, &quot;dodgerblue&quot;)) + ggtitle(&quot;Predicted versus simulated values&quot;) + theme_bw() 4.2.9 Analyze the simulated data # fit a linear mixed-effects model to data mod_sim &lt;- lmer(liking_ij ~ 1 + genre_i + (1 + genre_i | subj_id), data = dat_sim) summary(mod_sim, corr = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: liking_ij ~ 1 + genre_i + (1 + genre_i | subj_id) ## Data: dat_sim ## ## REML criterion at convergence: 35420.2 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.6472 -0.6360 0.0059 0.6720 3.0856 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## subj_id (Intercept) 51.01 7.142 ## genre_i 13.57 3.684 0.07 ## Residual 63.17 7.948 ## Number of obs: 5000, groups: subj_id, 100 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 65.3436 0.7317 99.0003 89.31 &lt;2e-16 *** ## genre_i 15.9134 0.4316 99.0000 36.87 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Use broom.mixed::tidy(mod_sim) to get a tidy table of the results. Below, we added column “parameter” and “value”, so you can compare the estimate from the model to the parameters you used to simulate the data. # get a tidy table of results broom.mixed::tidy(mod_sim) |&gt; mutate_if(is.numeric, round, 3) |&gt; mutate( parameter = c(&quot;beta_0&quot;, &quot;beta_1&quot;, &quot;tau_0&quot;, &quot;rho&quot;, &quot;tau_1&quot;, &quot;sigma&quot;), value = c(beta_0, beta_1, tau_0, rho, tau_1, sigma), ) |&gt; select(term, parameter, value, estimate) |&gt; knitr::kable() term parameter value estimate (Intercept) beta_0 65.0 65.344 genre_i beta_1 15.0 15.913 sd__(Intercept) tau_0 7.0 7.142 cor__(Intercept).genre_i rho 0.2 0.068 sd__genre_i tau_1 4.0 3.684 sd__Observation sigma 8.0 7.948 4.3 Data simulation automated Now that we’ve tested the data generating code, we can put it into a function so that it’s easy to run it repeatedly. # set up the custom data simulation function sim_data &lt;- function( n_subj = 100, # number of subjects n_pop = 25, # number of pop songs n_rock = 25, # number of rock songs beta_0 = 65, # mean for pop genre beta_1 = 15, # effect of genre tau_0 = 7, # by-subject random intercept sd tau_1 = 4, # by-subject random slope sd rho = 0.2, # correlation between intercept and slope sigma = 8 # residual (standard deviation) ) { # simulate a sample of songs songs &lt;- tibble( song_id = seq_len(n_pop + n_rock), category = rep(c(&quot;pop&quot;, &quot;rock&quot;), c(n_pop, n_rock)), genre_i = rep(c(0, 1), c(n_pop, n_rock)) ) # simulate a sample of subjects subjects &lt;- faux::rnorm_multi( n = n_subj, mu = 0, sd = c(tau_0, tau_1), r = rho, varnames = c(&quot;b_0j&quot;, &quot;b_1j&quot;) ) |&gt; mutate(subj_id = seq_len(n_subj)) # cross subject and song IDs crossing(subjects, songs) |&gt; mutate(e_ij = rnorm(n(), mean = 0, sd = sigma), liking_ij = beta_0 + b_0j + (beta_1 + b_1j) * genre_i + e_ij) |&gt; select(subj_id, category, genre_i, liking_ij) } 4.4 Power calculation (single run) We can wrap the data generating function and analysis code in a new function (power_run()) that returns a tidy table of the analysis results. # set up the power function power_run &lt;- function(...) { # ... is a shortcut that forwards any additional arguments to sim_data() dat_sim &lt;- sim_data(...) mod_sim &lt;- suppressWarnings({ suppressMessages({ lmerTest::lmer(liking_ij ~ 1 + genre_i + (1 + genre_i | subj_id), data = dat_sim) })}) broom.mixed::tidy(mod_sim) } # run one model with default parameters power_run() ## # A tibble: 6 × 8 ## effect group term estimate std.error statistic df p.value ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 fixed &lt;NA&gt; (Intercept) 64.8 0.679 95.4 99.0 2.92e-99 ## 2 fixed &lt;NA&gt; genre_i 15.4 0.476 32.3 99.0 2.23e-54 ## 3 ran_pars subj_id sd__(Intercept) 6.59 NA NA NA NA ## 4 ran_pars subj_id cor__(Intercep… 0.271 NA NA NA NA ## 5 ran_pars subj_id sd__genre_i 4.19 NA NA NA NA ## 6 ran_pars Residual sd__Observation 8.05 NA NA NA NA # run one model with new parameters power_run(n_pop = 50, n_rock = 25, beta_1 = 5) ## # A tibble: 6 × 8 ## effect group term estimate std.error statistic df p.value ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 fixed &lt;NA&gt; (Intercept) 65.2 0.763 85.5 99.0 1.32e-94 ## 2 fixed &lt;NA&gt; genre_i 5.65 0.401 14.1 99.0 2.12e-25 ## 3 ran_pars subj_id sd__(Intercept) 7.54 NA NA NA NA ## 4 ran_pars subj_id cor__(Intercep… 0.154 NA NA NA NA ## 5 ran_pars subj_id sd__genre_i 3.50 NA NA NA NA ## 6 ran_pars Residual sd__Observation 7.98 NA NA NA NA 4.5 Power calculation automated To get an accurate estimation of power, we need to run the simulation many times. We use 100 here as an example, but the results will be more accurate the more replications you run. This will depend on the specifics of your analysis, but we recommend at least 1000 replications. reps &lt;- 100 sims &lt;- map_df(1:reps, ~ power_run()) # calculate mean estimates and power for specified alpha alpha &lt;- 0.05 sims |&gt; filter(term == &quot;genre_i&quot;) |&gt; group_by(term) |&gt; summarise( mean_estimate = mean(estimate), mean_se = mean(std.error), power = mean(p.value &lt; alpha), .groups = &quot;drop&quot; ) ## # A tibble: 1 × 4 ## term mean_estimate mean_se power ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 genre_i 15.1 0.459 1 4.5.1 Check false positive rate Set the effect of genre_ij to 0 to calculate the false positive rate. This is the probability of concluding there is an effect when there is no actual effect in your population. # run simulations and calculate the false positive rate reps &lt;- 100 sims_fp &lt;- map_df(1:reps, ~ power_run(beta_1 = 0)) # calculate mean estimates and power for specified alpha alpha &lt;- 0.05 sims_fp |&gt; filter(term == &quot;genre_i&quot;) |&gt; summarise(power = mean(p.value &lt; alpha)) ## # A tibble: 1 × 1 ## power ## &lt;dbl&gt; ## 1 0.09 Ideally, the false positive rate will be equal to alpha, which we set here at 0.05. 4.6 Power for different effect sizes In real life, we will not know the effect size of our quantity of interest and so we will need to repeatedly perform the power analysis over a range of different plausible effect sizes. # grid of paramater values pgrid &lt;- crossing( n_subj = c(10, 25, 50, 100), n_pop = c(10, 50), n_rock = c(10, 50), beta_1 = 1:5 ) # fit the models over the parameters parameter_search &lt;- function(params = pgrid){ future_pmap_dfr( .l = params, .f = ~ power_run(n_subj = ..1, n_pop = ..2, n_rock = ..3, beta_1 = ..4), .options = furrr_options(seed = TRUE), .progress = TRUE ) } Fair warning, this will take some time! # replicate parameter search 100 times reps &lt;- 100 # replicate each row of the parameter grid to match the dimensions of the model outputs pgrid_expand &lt;- pgrid |&gt; slice(rep(1:n(), each = 6)) |&gt; # expand by 6 parameters map_df(rep.int, times = reps) # expand by number of reps sims_params &lt;- future_replicate( n = reps, expr = parameter_search(), simplify = FALSE ) |&gt; imap( ~ mutate(.x, rep = .y, .before = &quot;effect&quot;)) |&gt; bind_rows() |&gt; mutate(pgrid_expand, .before = &quot;effect&quot;) # add in the parameter grid # calculate mean estimates and power for specified alpha alpha &lt;- 0.05 sims_table &lt;- sims_params |&gt; filter(term == &quot;genre_i&quot;) |&gt; group_by(term, n_subj, n_pop, n_rock, beta_1) |&gt; summarise( mean_estimate = mean(estimate), mean_se = mean(std.error), power = mean(p.value &lt; alpha), .groups = &quot;drop&quot; ) Here’s the table from the simulation. sims_table |&gt; gt() |&gt; tab_header(title = &quot;Power values for GLM&quot;) |&gt; data_color( columns = power, colors = scales::col_numeric( palette = c(&quot;red&quot;, &quot;green&quot;), domain = c(0, 1) ) ) #odyeznexyg table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #odyeznexyg thead, #odyeznexyg tbody, #odyeznexyg tfoot, #odyeznexyg tr, #odyeznexyg td, #odyeznexyg th { border-style: none; } #odyeznexyg p { margin: 0; padding: 0; } #odyeznexyg .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #odyeznexyg .gt_caption { padding-top: 4px; padding-bottom: 4px; } #odyeznexyg .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #odyeznexyg .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #odyeznexyg .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #odyeznexyg .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #odyeznexyg .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #odyeznexyg .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #odyeznexyg .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #odyeznexyg .gt_column_spanner_outer:first-child { padding-left: 0; } #odyeznexyg .gt_column_spanner_outer:last-child { padding-right: 0; } #odyeznexyg .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #odyeznexyg .gt_spanner_row { border-bottom-style: hidden; } #odyeznexyg .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #odyeznexyg .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #odyeznexyg .gt_from_md > :first-child { margin-top: 0; } #odyeznexyg .gt_from_md > :last-child { margin-bottom: 0; } #odyeznexyg .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #odyeznexyg .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #odyeznexyg .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #odyeznexyg .gt_row_group_first td { border-top-width: 2px; } #odyeznexyg .gt_row_group_first th { border-top-width: 2px; } #odyeznexyg .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #odyeznexyg .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #odyeznexyg .gt_first_summary_row.thick { border-top-width: 2px; } #odyeznexyg .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #odyeznexyg .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #odyeznexyg .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #odyeznexyg .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #odyeznexyg .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #odyeznexyg .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #odyeznexyg .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #odyeznexyg .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #odyeznexyg .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #odyeznexyg .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #odyeznexyg .gt_left { text-align: left; } #odyeznexyg .gt_center { text-align: center; } #odyeznexyg .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #odyeznexyg .gt_font_normal { font-weight: normal; } #odyeznexyg .gt_font_bold { font-weight: bold; } #odyeznexyg .gt_font_italic { font-style: italic; } #odyeznexyg .gt_super { font-size: 65%; } #odyeznexyg .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #odyeznexyg .gt_asterisk { font-size: 100%; vertical-align: 0; } #odyeznexyg .gt_indent_1 { text-indent: 5px; } #odyeznexyg .gt_indent_2 { text-indent: 10px; } #odyeznexyg .gt_indent_3 { text-indent: 15px; } #odyeznexyg .gt_indent_4 { text-indent: 20px; } #odyeznexyg .gt_indent_5 { text-indent: 25px; } Power values for GLM term n_subj n_pop n_rock beta_1 mean_estimate mean_se power genre_i 10 10 10 1 1.2916490 1.6928108 0.09 genre_i 10 10 10 2 2.3196518 1.6938221 0.24 genre_i 10 10 10 3 3.3714006 1.6889789 0.41 genre_i 10 10 10 4 4.3800208 1.6845269 0.59 genre_i 10 10 10 5 5.3739998 1.6838954 0.84 genre_i 10 10 50 1 1.1881422 1.4837541 0.09 genre_i 10 10 50 2 2.1602927 1.4909269 0.24 genre_i 10 10 50 3 3.1225753 1.4948799 0.43 genre_i 10 10 50 4 4.1231073 1.4949390 0.65 genre_i 10 10 50 5 5.1374754 1.4936506 0.85 genre_i 10 50 10 1 1.1051200 1.4538446 0.11 genre_i 10 50 10 2 2.1053024 1.4531383 0.27 genre_i 10 50 10 3 3.0989963 1.4570028 0.42 genre_i 10 50 10 4 4.1148664 1.4652887 0.69 genre_i 10 50 10 5 5.1294860 1.4608603 0.86 genre_i 10 50 50 1 1.1306933 1.3123858 0.16 genre_i 10 50 50 2 2.1425977 1.3164130 0.30 genre_i 10 50 50 3 3.1446112 1.3167400 0.49 genre_i 10 50 50 4 4.1484092 1.3200936 0.78 genre_i 10 50 50 5 5.1738607 1.3186065 0.90 genre_i 25 10 10 1 1.0008540 1.0700923 0.16 genre_i 25 10 10 2 2.0092374 1.0693354 0.42 genre_i 25 10 10 3 3.0159328 1.0700988 0.77 genre_i 25 10 10 4 4.0429368 1.0693436 0.94 genre_i 25 10 10 5 5.0580180 1.0685673 1.00 genre_i 25 10 50 1 1.0742274 0.9809737 0.15 genre_i 25 10 50 2 2.0631444 0.9780480 0.52 genre_i 25 10 50 3 3.0760352 0.9781825 0.88 genre_i 25 10 50 4 4.0861663 0.9801514 0.97 genre_i 25 10 50 5 5.0800436 0.9807959 1.00 genre_i 25 50 10 1 1.0700274 0.9758720 0.15 genre_i 25 50 10 2 2.0626648 0.9755446 0.60 genre_i 25 50 10 3 3.0468364 0.9754874 0.85 genre_i 25 50 10 4 4.0397111 0.9741303 0.96 genre_i 25 50 10 5 5.0481469 0.9744679 1.00 genre_i 25 50 50 1 0.9550583 0.8594456 0.15 genre_i 25 50 50 2 1.9460141 0.8537143 0.60 genre_i 25 50 50 3 2.9523440 0.8559966 0.95 genre_i 25 50 50 4 3.9488157 0.8577228 1.00 genre_i 25 50 50 5 4.9286471 0.8582921 1.00 genre_i 50 10 10 1 0.9421465 0.7540682 0.25 genre_i 50 10 10 2 1.9360642 0.7535628 0.66 genre_i 50 10 10 3 2.9379936 0.7525021 0.97 genre_i 50 10 10 4 3.9513785 0.7547758 1.00 genre_i 50 10 10 5 4.9251219 0.7548611 1.00 genre_i 50 10 50 1 0.9650878 0.6817676 0.34 genre_i 50 10 50 2 1.9690711 0.6810026 0.78 genre_i 50 10 50 3 2.9714998 0.6831476 0.99 genre_i 50 10 50 4 3.9663534 0.6847466 1.00 genre_i 50 10 50 5 4.9635980 0.6844836 1.00 genre_i 50 50 10 1 1.0094476 0.6861145 0.28 genre_i 50 50 10 2 2.0194583 0.6867160 0.81 genre_i 50 50 10 3 3.0287801 0.6858773 1.00 genre_i 50 50 10 4 4.0137710 0.6857318 1.00 genre_i 50 50 10 5 5.0170555 0.6852248 1.00 genre_i 50 50 50 1 1.0585229 0.6033823 0.40 genre_i 50 50 50 2 2.0668316 0.6027647 0.88 genre_i 50 50 50 3 3.0617743 0.6020371 1.00 genre_i 50 50 50 4 4.0642297 0.6023047 1.00 genre_i 50 50 50 5 5.0878340 0.6029569 1.00 genre_i 100 10 10 1 1.0054151 0.5377233 0.46 genre_i 100 10 10 2 1.9996983 0.5370384 0.96 genre_i 100 10 10 3 3.0016049 0.5366826 1.00 genre_i 100 10 10 4 4.0134499 0.5365604 1.00 genre_i 100 10 10 5 5.0120276 0.5357372 1.00 genre_i 100 10 50 1 1.0073129 0.4832086 0.54 genre_i 100 10 50 2 1.9982556 0.4824011 0.97 genre_i 100 10 50 3 2.9958209 0.4835456 1.00 genre_i 100 10 50 4 3.9916367 0.4833174 1.00 genre_i 100 10 50 5 4.9916986 0.4835192 1.00 genre_i 100 50 10 1 0.9803665 0.4868805 0.55 genre_i 100 50 10 2 1.9765135 0.4872434 0.94 genre_i 100 50 10 3 2.9726877 0.4878173 1.00 genre_i 100 50 10 4 3.9735508 0.4881493 1.00 genre_i 100 50 10 5 4.9668595 0.4884530 1.00 genre_i 100 50 50 1 0.9978797 0.4323592 0.71 genre_i 100 50 50 2 1.9959194 0.4321628 0.99 genre_i 100 50 50 3 3.0005304 0.4312985 1.00 genre_i 100 50 50 4 4.0002161 0.4310073 1.00 genre_i 100 50 50 5 4.9933763 0.4309799 1.00 Here’s the graph from the simulation. sims_table |&gt; mutate(across(n_subj:beta_1, as.factor)) |&gt; ggplot(aes(x = mean_estimate, y = power, group = n_subj, color = n_subj)) + geom_line() + geom_point(size = 2) + facet_grid(n_pop ~ n_rock) + ylim(0, 1) + theme_bw() "],["python.html", "5 Python 5.1 Simple linear regression 5.2 Mixed effects model", " 5 Python 5.1 Simple linear regression 5.1.1 Setup First, let’s import the libraries used for simulation based power analysis in Python. import random import numpy as np import pandas as pd from sklearn.linear_model import LinearRegression import statsmodels.api as sm import scipy import matplotlib.pyplot as plt We will also set the pseudo-random number generator seed to 02138 to make the stochastic components of our simulations reproducible. np.random.seed(02138) 5.1.2 Step 4: Simulate Next, we create a simulated dataset based on our assumptions about the model under the alternative hypothesis, and fit the model. def generate_dataset(sample_size, interact_coef): data_set = [] for i in range(sample_size): _id = i age = np.random.randint(18,66) female = np.random.choice([0, 1]) interact = age * female e = np.random.normal(0, 20) sbp = 110 + 0.5*age + (-20)*female + interact_coef*interact + e data_set.append([_id, age, female, interact, e, sbp]) data_set = pd.DataFrame(data_set) data_set.columns = [&quot;_id&quot;, &quot;age&quot;, &quot;female&quot;, &quot;interact&quot;, &#39;e&#39;, &quot;sbp&quot;] return data_set 5.1.3 Step 5: Automate Next, let’s write a function that creates datasets under the alternative hypothesis, fits the models, and uses a likelihood-ratio test to calculate power. def cal_power(sample_size, interact_coef, simiu_cnt, alpha): power_list = [] for i in range(simiu_cnt): dataset = generate_dataset(sample_size, interact_coef) y1 = dataset[&#39;sbp&#39;] x1 = dataset[[&#39;age&#39;, &#39;female&#39;, &#39;interact&#39;]] x1 = sm.add_constant(x1) full_model = sm.OLS(y1, x1).fit() full_ll = full_model.llf y2 = dataset[&#39;sbp&#39;] x2 = dataset[[&#39;age&#39;, &#39;female&#39;]] x2 = sm.add_constant(x2) reduced_model = sm.OLS(y2, x2).fit() reduced_ll = reduced_model.llf LR_statistic = -2*(reduced_ll-full_ll) power = scipy.stats.chi2.sf(LR_statistic, 1) if power&lt;=alpha: power_list.append(1) else: power_list.append(0) mean_power = sum(power_list)/len(power_list) return [sample_size, interact_coef, mean_power] result = [] for i in range(400, 800, 100): for j in [0.2, 0.25, 0.3, 0.35, 0.4]: result.append(cal_power(sample_size = i, interact_coef = j, simiu_cnt = 1000, alpha = 0.05)) result = pd.DataFrame(result) result.columns = [&#39;N&#39;, &#39;interact_coef&#39;, &#39;Power&#39;] result 5.1.4 Step 6: Summarize In this part, we export the results of the simulations which include two parts: a table and a graph showing the results from the simulations. It should be noted that the graph from Python simulation is a little bit different from that in Stata, and this is mainly caused by different simulation process within Stata and Python. N interact_coef Power 0 400 0.20 0.320 1 400 0.25 0.413 2 400 0.30 0.557 3 400 0.35 0.664 4 400 0.40 0.798 5 500 0.20 0.328 6 500 0.25 0.513 7 500 0.30 0.636 8 500 0.35 0.788 9 500 0.40 0.869 10 600 0.20 0.406 11 600 0.25 0.569 12 600 0.30 0.714 13 600 0.35 0.829 14 600 0.40 0.926 15 700 0.20 0.447 16 700 0.25 0.601 17 700 0.30 0.776 18 700 0.35 0.887 19 700 0.40 0.955 n_list = result[&#39;N&#39;].unique() color_list = [&#39;darkblue&#39;, &#39;firebrick&#39;, &#39;darkgreen&#39;, &#39;orange&#39;] plt.figure(figsize=(15,6)) for i in range(len(n_list)): n = n_list[i] c = color_list[i] plt.plot(result[result[&#39;N&#39;]==n][&#39;interact_coef&#39;], result[result[&#39;N&#39;]==n][&#39;Power&#39;], &#39;o-&#39;, color = c) plt.grid() plt.xticks([0.2, 0.25, 0.3, 0.35, 0.4], fontsize = 12) plt.yticks([0.2, 0.4, 0.6, 0.8, 1], fontsize = 12) plt.xlabel(&#39;interact&#39;, fontsize = 15) plt.ylabel(&#39;Power&#39;, fontsize = 15) plt.legend(result[&#39;N&#39;].unique(), fontsize = 12) plt.title(&#39;Estimate Power: Two-sided Test&#39;, fontsize = 18) plt.show() 5.2 Mixed effects model For the mixed effects model example, we will continue to use the same Python libraries and pseudo-random number generator seed as previously. 5.2.1 Step 4: Simulate Next, we create a simulated dataset based on our assumptions about the model under the alternative hypothesis, and fit the model. We will simulate 5 observations at 4-month increments for 200 children. def generate_dataset(sample_size, obser_cnt): data_set = [] for i in range(sample_size): child_id = i female_origin = np.random.choice([0, 1]) u_0i_origin = np.random.normal(0, 0.25) u_1i_origin = np.random.normal(0, 0.60) for j in range(obser_cnt): child = child_id female = female_origin age = 0.5*j u_0i = u_0i_origin u_1i = u_1i_origin interaction = age * female e_ij = np.random.normal(0, 1.2) weight = 5.35 + 3.6*age + (-0.5)*female + (-0.25)*interaction + u_0i + age*u_1i + e_ij data_set.append([child, female, age, u_0i, u_1i, interaction, e_ij, weight]) data_set = pd.DataFrame(data_set) data_set.columns = [&quot;child_id&quot;, &quot;female&quot;, &quot;age&quot;, &quot;u_0i&quot;, &quot;u_li&quot;, &quot;interaction&quot;, &quot;e_ij&quot;, &quot;weight&quot;] return data_set 5.2.2 Step 5: Automate Next, let’s write a function that creates datasets under the alternative hypothesis, fits the mixed effects models, tests the null hypothesis of interest, and uses a for loop to run many iterations of the function. def cal_power(sample_size, obser_cnt, simiu_cnt, alpha): power_list = [] for i in range(simiu_cnt): dataset = generate_dataset(sample_size, obser_cnt) y1 = dataset[&#39;weight&#39;] x1 = dataset[[&#39;female&#39;, &#39;age&#39;, &#39;interaction&#39;]] x1 = sm.add_constant(x1) full_model = sm.OLS(y1, x1).fit() full_ll = full_model.llf y2 = dataset[&#39;weight&#39;] x2 = dataset[[&#39;female&#39;, &#39;age&#39;]] x2 = sm.add_constant(x2) reduced_model = sm.OLS(y2, x2).fit() reduced_ll = reduced_model.llf LR_statistic = -2*(reduced_ll-full_ll) power = scipy.stats.chi2.sf(LR_statistic, 1) if power&lt;=alpha: power_list.append(1) else: power_list.append(0) mean_power = sum(power_list)/len(power_list) return [obser_cnt, sample_size, mean_power] result = [] for i in range(100, 600, 100): for j in range(5, 7): result.append(cal_power(sample_size = i, obser_cnt = j, simiu_cnt = 1000, alpha = 0.05)) result = pd.DataFrame(result) result.columns = [&#39;n1&#39;, &#39;N&#39;, &#39;Power&#39;] result 5.2.3 Step 6: Summarize The last procedure is to export the results which contain a table and a graph. n1 N Power 0 5 100 0.290 1 6 100 0.398 2 5 200 0.491 3 6 200 0.632 4 5 300 0.655 5 6 300 0.798 6 5 400 0.779 7 6 400 0.917 8 5 500 0.857 9 6 500 0.940 n1_list = result[&#39;n1&#39;].unique() color_list = [&#39;darkblue&#39;, &#39;firebrick&#39;] plt.figure(figsize=(15,6)) for i in range(len(n1_list)): n = n1_list[i] c = color_list[i] plt.plot(result[result[&#39;n1&#39;]==n][&#39;N&#39;], result[result[&#39;n1&#39;]==n][&#39;Power&#39;], &#39;-o&#39;, color = c) plt.grid() plt.xticks([100, 200, 300, 400, 500], fontsize = 12) plt.yticks([0.2, 0.4, 0.6, 0.8, 1], fontsize = 12) plt.xlabel(&#39;Level 2 Sample Size&#39;, fontsize = 15) plt.ylabel(&#39;Power&#39;, fontsize = 15) plt.legend(result[&#39;n1&#39;].unique(), fontsize = 12) plt.title(&#39;Power: Two-sided Test&#39;, fontsize = 18) plt.show() "],["stata.html", "6 Stata 6.1 Simple linear regression 6.2 Mixed effects model", " 6 Stata 6.1 Simple linear regression 6.1.1 Setup We will also set the pseudo-random number generator seed to 02138 to make the stochastic components of our simulations reproducible. set seed 02138 6.1.2 Step 4: Simulate Next, we create a simulated dataset based on our assumptions about the model under the alternative hypothesis, and fit the model. clear set obs 400 generate age = runiformint(18,65) generate female = rbinomial(1,0.5) generate interact = age*female generate e = rnormal(0,20) generate sbp = 110 + 0.5*age + (-20)*female + 0.35*interact + e We can then test the null hypothesis that the interaction term equals zero using a likelihood-ratio test. regress sbp age i.female c.age#i.female estimates store full regress sbp age i.female estimates store reduced Likelihood-ratio test LR chi2(1) = 13.38 (Assumption: reduced nested in full) Prob &gt; chi2 = 0.0003 The test yields a p-value of 0.0003. return list scalars: r(p) = .0002540647000293 r(chi2) = 13.38189649447986 r(df) = 1 local reject = (r(p)&lt;0.05) 6.1.3 Step 5: Automate Next, let’s write a program that creates datasets under the alternative hypothesis, fits the models, and uses the simulate command to test the program. capture program drop simregress program simregress, rclass version 16 // DEFINE THE INPUT PARAMETERS AND THEIR DEFAULT VALUES syntax, n(integer) /// Sample size [ alpha(real 0.05) /// Alpha level intercept(real 110) /// Intercept parameter age(real 0.5) /// Age parameter female(real -20) /// Female parameter interact(real 0.35) /// Interaction parameter esd(real 20) ] // Standard deviation of the error quietly { // GENERATE THE RANDOM DATA clear set obs `n&#39; generate age = runiformint(18,65) generate female = rbinomial(1,0.5) generate interact = age*female generate e = rnormal(0,`esd&#39;) generate sbp = `intercept&#39; + `age&#39;*age + `female&#39;*female + /// `interact&#39;*interact + e // TEST THE NULL HYPOTHESIS regress sbp age i.female c.age#i.female estimates store full regress sbp age i.female estimates store reduced lrtest full reduced } // RETURN RESULTS return scalar reject = (r(p)&lt;`alpha&#39;) end Below, we use simulate to run simregress 200 times and summarize the variable reject. The results indicate that we would have 74% power to detect an interaction parameter of 0.35 given a sample of 400 participants and the other assumptions about the model. simulate reject=r(reject), reps(200) seed(12345): /// simttest, n(200) m0(70) ma(75) sd(15) alpha(0.05) Simulations (200) ----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5 .................................................. 50 .................................................. 100 .................................................. 150 .................................................. 200 summarize reject Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- reject | 200 .735 .4424407 0 1 Next, let’s write a program called power\\_cmd\\_simregress so that we can integrate simregress into Stata’s power command. capture program drop power_cmd_simregress program power_cmd_simregress, rclass version 17 // DEFINE THE INPUT PARAMETERS AND THEIR DEFAULT VALUES syntax, n(integer) /// Sample size [ alpha(real 0.05) /// Alpha level intercept(real 110) /// Intercept parameter age(real 0.5) /// Age parameter female(real -20) /// Female parameter interact(real 0.35) /// Interaction parameter esd(real 20) /// Standard deviation of the error reps(integer 100)] // Number of repetitions // GENERATE THE RANDOM DATA AND TEST THE NULL HYPOTHESIS quietly { simulate reject=r(reject), reps(`reps&#39;): /// simregress, n(`n&#39;) age(`age&#39;) female(`female&#39;) /// interact(`interact&#39;) esd(`esd&#39;) alpha(`alpha&#39;) summarize reject } // RETURN RESULTS return scalar power = r(mean) return scalar N = `n&#39; return scalar alpha = `alpha&#39; return scalar intercept = `intercept&#39; return scalar age = `age&#39; return scalar female = `female&#39; return scalar interact = `interact&#39; return scalar esd = `esd&#39; end Finally, run power simregress for a range of input parameter values, including the parameters listed in double quotes. To do this, we first need to create a program called power\\_cmd\\_simregress\\_init. capture program drop power_cmd_simregress_init program power_cmd_simregress_init, sclass sreturn local pss_colnames &quot;intercept age female interact esd&quot; sreturn local pss_numopts &quot;intercept age female interact esd&quot; end 6.1.4 Step 6: Summarize Now, we’re ready to use power simregress! The output below shows the simulated power when the interaction parameter equals 0.2 to 0.4 in increments of 0.05 for samples of size 400, 500, 600, and 700. power simregress, n(400(100)700) intercept(110) /// age(0.5) female(-20) interact(0.2(0.05)0.4) /// reps(1000) table graph(xdimension(interact) /// legend(rows(1))) Estimated power Two-sided test +--------------------------------------------------------------------+ | alpha power N intercept age female interact esd | |--------------------------------------------------------------------| | .05 .3 400 110 .5 -20 .2 20 | | .05 .421 400 110 .5 -20 .25 20 | | .05 .546 400 110 .5 -20 .3 20 | | .05 .685 400 110 .5 -20 .35 20 | | .05 .767 400 110 .5 -20 .4 20 | | .05 .34 500 110 .5 -20 .2 20 | | .05 .509 500 110 .5 -20 .25 20 | | .05 .63 500 110 .5 -20 .3 20 | | .05 .767 500 110 .5 -20 .35 20 | | .05 .872 500 110 .5 -20 .4 20 | | .05 .412 600 110 .5 -20 .2 20 | | .05 .556 600 110 .5 -20 .25 20 | | .05 .712 600 110 .5 -20 .3 20 | | .05 .829 600 110 .5 -20 .35 20 | | .05 .886 600 110 .5 -20 .4 20 | | .05 .471 700 110 .5 -20 .2 20 | | .05 .634 700 110 .5 -20 .25 20 | | .05 .771 700 110 .5 -20 .3 20 | | .05 .908 700 110 .5 -20 .35 20 | | .05 .957 700 110 .5 -20 .4 20 | +--------------------------------------------------------------------+ 6.2 Mixed effects model 6.2.1 Setup Again, we set the seed to 02138. set seed 02138 6.2.2 Step 4: Simulate Next, we create a simulated dataset based on our assumptions about the model under the alternative hypothesis, and fit the model. We will simulate 5 observations at 4-month increments for 200 children. clear set obs 200 generate child = _n generate female = rbinomial(1,0.5) generate u_0i = rnormal(0,0.25) generate u_1i = rnormal(0,0.60) expand 5 bysort child: generate age = (_n-1)*0.5 generate interaction = age*female generate e_ij = rnormal(0,1.2) generate weight = 5.35 + 3.6*age + (-0.5)*female + (-0.25)*interaction /// + u_0i + age*u_1i + e_ij Our dataset includes the random deviations that we would not observe in a real dataset. We can then use mixed to fit a model to our simulated data. mixed weight age i.female c.age#i.female || child: age , stddev nolog noheader estimates store full mixed weight age i.female || child: age , stddev nolog noheader estimates store reduced lrtest full reduced We can then test the null hypothesis that the interaction term equals zero using a likelihood-ratio test. lrtest full reduced Likelihood-ratio test LR chi2(1) = 8.23 (Assumption: reduced nested in full) Prob &gt; chi2 = 0.0041 The \\(p\\)-value for our test is 0.0041, so we would reject the null hypothesis that the interaction term equals zero. 6.2.3 Step 5: Automate Next, let’s write a program that creates datasets under the alternative hypothesis, fits the mixed effects models, tests the null hypothesis of interest, and uses the simulate command to run many iterations of the program. capture program drop simmixed program simmixed, rclass version 16 // PARSE INPUT syntax, n1(integer) /// n(integer) /// [ alpha(real 0.05) /// intercept(real 5.35) /// age(real 3.6) /// female(real -0.5) /// interact(real -0.25) /// u0i(real 0.25) /// u1i(real 0.60) /// eij(real 1.2) ] // COMPUTE POWER quietly { drop _all set obs `n&#39; generate child = _n generate female = rbinomial(1,0.5) generate u_0i = rnormal(0,`u0i&#39;) generate u_1i = rnormal(0,`u1i&#39;) expand `n1&#39; bysort child: generate age = (_n-1)*0.5 generate interaction = age*female generate e_ij = rnormal(0,`eij&#39;) generate weight = `intercept&#39; + `age&#39;*age + `female&#39;*female + /// `interact&#39;*interaction + u_0i + age*u_1i + e_ij mixed weight age i.female c.age#i.female || child: age, iter(200) local conv1 = e(converged) estimates store full mixed weight age i.female || child: age, iter(200) local conv2 = e(converged) estimates store reduced lrtest full reduced local reject = cond(`conv1&#39; + `conv2&#39;==2, (r(p)&lt;`alpha&#39;), .) } // RETURN RESULTS return scalar reject = `reject&#39; return scalar conv = `conv1&#39;+`conv2&#39; end We then use simulate to run simmixed 10 times using the default parameter values for 5 observations on each of 200 children. simulate reject=r(reject) converged=r(conv), reps(10) seed(12345): simmixed, n1(5) n(200) command: simmixed, n1(5) n(200) reject: r(reject) converged: r(conv) Simulations (10) ----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5 simulate saved the results of the hypothesis tests to a variable named reject. The mean of reject is our estimate of the power to test the null hypothesis that the age×sex interaction term equals zero, assuming that the weight of 200 children is measured 5 times. We could stop with our quick simulation if we were interested only in a specific set of assumptions. But it’s easy to write an additional program named power\\_cmd\\_simmixed that will allow us to use Stata’s power command to create tables and graphs for a range of sample sizes. capture program drop power_cmd_simmixed program power_cmd_simmixed, rclass version 16 // PARSE INPUT syntax, n1(integer) /// n(integer) /// [ alpha(real 0.05) /// intercept(real 5.35) /// age(real 3.6) /// female(real -0.5) /// interact(real -0.25) /// u0i(real 0.25) /// u1i(real 0.60) /// eij(real 1.2) /// reps(integer 1000) ] // COMPUTE POWER quietly { simulate reject=r(reject), reps(`reps&#39;): /// simmixed, n1(`n1&#39;) n(`n&#39;) alpha(`alpha&#39;) intercept(`intercept&#39;) /// age(`age&#39;) female(`female&#39;) interact(`interact&#39;) /// u0i(`u0i&#39;) u1i(`u1i&#39;) eij(`eij&#39;) summarize reject } // RETURN RESULTS return scalar power = r(mean) return scalar n1 = `n1&#39; return scalar N = `n&#39; return scalar alpha = `alpha&#39; return scalar intercept = `intercept&#39; return scalar age = `age&#39; return scalar female = `female&#39; return scalar interact = `interact&#39; return scalar u0i = `u0i&#39; return scalar u1i = `u1i&#39; return scalar eij = `eij&#39; end It’s also easy to write a program named power\\_cmd\\_simmixed\\_init that will allow us to simulate power for a range of values for the parameters in our model. capture program drop power_cmd_simmixed_init program power_cmd_simmixed_init, sclass version 16 sreturn clear // ADD COLUMNS TO THE OUTPUT TABLE sreturn local pss_colnames &quot;n1 intercept age female interact u0i u1i eij&quot; // ALLOW NUMLISTS FOR ALL PARAMETERS sreturn local pss_numopts &quot;n1 intercept age female interact u0i u1i eij&quot; end 6.2.4 Step 6: Summarize Now, we can use power simmixed to simulate power for a variety of assumptions. The example below simulates power for a range of sample sizes at both levels 1 and 2. Level 2 sample sizes range from 100 to 500 children in increments of 100. At level 1, we consider 5 and 6 observations per child. power simmixed, n1(5 6) n(100(100)500) reps(1000) table(n1 N power) graph(ydimension(power) xdimension(N) plotdimension(n1) xtitle(Level 2 Sample Size) legend(title(Level 1 Sample Size))) xxxxxxxxxxxxxxxxxxxxxxxxxxx Estimated power Two-sided test +-------------------------+ | n1 N power | |-------------------------| | 5 100 .2629 | | 6 100 .313 | | 5 200 .397 | | 6 200 .569 | | 5 300 .621 | | 6 300 .735 | | 5 400 .734 | | 6 400 .855 | | 5 500 .828 | | 6 500 .917 | +-------------------------+ "],["software-comparison.html", "7 Software Comparison", " 7 Software Comparison "],["resources.html", "Resources", " Resources We would like to acknowledge some excellent online and peer-reviewed material about power simulation and mixed effects models, which we have borrowed from liberally in the tutorial. These resouces represent an excellent next step in your exploration of simulation-based power analysis. R DeBruine &amp; Barr (2021) paper on using simulation to understand mixed effects models: https://journals.sagepub.com/doi/epdf/10.1177/2515245920965119 Julian Quandt’s 4-part blog series on power analysis via simulation: https://julianquandt.com/post/power-analysis-by-data-simulation-in-r-part-i/ https://julianquandt.com/post/power-analysis-by-data-simulation-in-r-part-ii/ https://julianquandt.com/post/power-analysis-by-data-simulation-in-r-part-iii/ https://julianquandt.com/post/power-analysis-by-data-simulation-in-r-part-iv/ Stata Chuck Huber’s 4-part blog series on power analysis via simulation: https://blog.stata.com/2019/01/10/calculating-power-using-monte-carlo-simulations-part-1-the-basics/ https://blog.stata.com/2019/01/29/calculating-power-using-monte-carlo-simulations-part-2-running-your-simulation-using-power/ https://blog.stata.com/2019/08/13/calculating-power-using-monte-carlo-simulations-part-3-linear-and-logistic-regression/ https://blog.stata.com/2019/08/20/calculating-power-using-monte-carlo-simulations-part-4-multilevel-longitudinal-models/ "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
