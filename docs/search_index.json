[["index.html", "Simulation-Based Power Analysis Table of Contents Contributors", " Simulation-Based Power Analysis This tutorial is designed to be a quick-start guide for conducting simulation-based power analyses in R, Python, and Stata. We focus particularly on power for mixed effects models, but the principles employed can be repurposed for any model and study design. The tutorial is suitable for anyone with a intermediate understanding of mixed effects models and coding in either R, Python, or Stata. While high-level packages exist in some of these languages for conducting power analysis (e.g., the R packages {simr}, {longpower}, and {simglm}), such packages abstract away the details of conducting simulations and thus are best used after gaining an understanding of the power simulation process. In addition, rolling your own simulations from scratch provides much more flexibility to tackle different study designs and models - and it’s fun! We are always grateful for any feedback you are willing to provide about our tutorials! Please email help@iq.harvard.edu with any thoughts. Table of Contents Canned Power Analysis Simulation-based Power Analysis Power of What? R Examples Python Examples Stata Examples Contributors The contents of these workshops are the result of a collaborative effort from members of the Data Science Services team at the Institute for Quantitative Social Science at Harvard University. The main contributors are Steve Worthington and Dan Yuan, with additional feedback from Jinjie Liu and Noah Greifer. "],["power-analysis.html", "1 Power Analysis 1.1 Canned routines 1.2 Step by step", " 1 Power Analysis Statistical power is the probability of detecting an effect of a given size, if such an effect exists. Or, equivalently, the probability of rejecting the null hypothesis when it is false. 1.1 Canned routines In some research designs, it can be an important step to calculate a priori statistical power. We use statistical power to determine the probability we can detect an effect of a given size, if such an effect does in fact exist. Or, equivalently, the probability of rejecting the null hypothesis when it is false. Researchers typically want to know the sample size required to reject a null hypothesis at a given power level, or alternatively, calculate power when sample size is fixed. In some situations, such as a randomized controlled trial with two groups, we can use a formula to calculate the sample size required to reject a null hypothesis. We will use an example to show how we do this. For instance, when we plan to perform a test of an hypothesis comparing the proportions of successes of tossing coins of faces in two independent populations, we would specify the following null and alternative hypotheses, respectively: \\[ H_0 :p_1 = p_2 \\] \\[ H_1 :p_1 \\neq p_2 \\] where \\(p_1 = p_2\\) are the proportions in the two populations for comparison. To make sure the test has a specific power, we can use the following formula to determine the sample sizes: \\[ N = 2(\\frac{z_{1-\\frac{\\alpha}{2}}+z_{1-\\beta}}{ES})^{2} \\] Where \\(n_i\\) is the sample size required in each group (\\(i=1,2\\)), \\(\\alpha\\) is the specific level of significance and \\(z_{1-\\frac{\\alpha}{2}}\\) is the critical value corresponding to the significance level. \\(1-\\beta\\) is the selected power and \\(z_{1-\\beta}\\) is the value from the standard normal distribution holding \\(1-\\beta\\) below it. ES is the effect size, defined as follows: \\[ ES = \\frac{|p_1 = p_2|}{\\sqrt{p(1-p)}} \\] where \\(|p_1 = p_2|\\) is the absolute value of the difference in proportions between the two groups under the alternative hypothesis, \\(H_1\\), and \\(p\\) is the proportion by pooling the observations from the two comparison groups. In Stata, we can use the following code to calculate the sample size needed to reject the null hypothesis that \\(H_0 :p_1 = p_2\\) (\\(H_1 :p_1 \\neq p_2\\)) given \\(\\hat{p_1} = 0.2, \\hat{p_2} = 0.6\\) on different fixed power levels: power twoproportions 0.2 0.6, n(40(20)100) graph 1.2 Step by step Specify a hypothesis test. Usually, there are several hypotheses in a research design, but for sample size calculation, make explicit a null and alternative hypothesis. Specify the significance level of the test. Usually \\(\\alpha = 0.05\\) is used, but other values could be substituted instead. Get the values of the parameters necessary to compute the power function. To solve for sample size \\(n\\), we need a value for the standard deviation and other parameters. Sometimes we need to use a pilot dataset to get these values. Specify the intended power of the test. The power of a test is the probability of finding significance if the alternative hypothesis is true. Calculate the needed sample size for the fixed power level. "],["simulation-based-power-analysis-1.html", "2 Simulation-Based Power Analysis 2.1 Step by step", " 2 Simulation-Based Power Analysis For some studies, formulas may not exist to calculate sample size, such as in complex study designs or when using mixed effects models for inference. In such cases, we must rely on simulation-based power analysis. The basic idea is to simulate running the study many times and calculate the proportion of times we reject the null hypothesis. This proportion provides an estimate of power. Generating a dataset and running an analysis for the hypothesis test is part of the simulation. One thing to mention is that randomness is usually introduced into the process through the dataset generation. For example, say the fixed power level is 95%, and you want to calculate the sample size using this level. You can take a “guess and check” method. With this method, firstly, you choose a sample size \\(n_1\\) and run the simulation to estimate your power. If power is estimated to be lower than 95%, you need to select a new value \\(n_2\\) that is larger than \\(n_1\\) running the simulation again. Multiple procedures are repeated until the estimated power is roughly 95%. As the example shows in the previous section, for several basic statistical tests, we can use Stata’s power command to calculate power and/or sample size. For more complicated analyses, however, such as those involving mixed effects models, we need to use a simulation-based approach. In these scenarios, we usually use the following procedures to perform power analysis: 2.1 Step by step Think Model specification: Write down the regression model, including all variables and parameters of interest. Variable composition: Specify the details of the covariates, such as the range of age or the proportion of females. Parameter composition: Establish reasonable values for the data-generating parameters in your model. Act Simulate: Simulate the sampling process for a single dataset, assuming the alternative hypothesis, and fit the model. Automate: Write a function/program/macro to create the datasets, fit the models, test the hypotheses of interest, and calculate power. The function/program/macro should allow for iterating power calculations over a grid of parameter values. Summarize: Summarize the output in tables and figures. "],["power-of-what.html", "3 Power of what? 3.1 Study design 3.2 Simple linear regression 3.3 Mixed effects model", " 3 Power of what? The initial steps of power simulation involve nothing more than thinking and writing down your thoughts using a pencil and paper. But, prior to walking through these steps, there is an even more fundamental issue to be addressed - the power of what? What quantity within your model do you wish to calculate power for? Overall model goodness-of-fit, individual parameters, or combinations of parameters? The point of entry for power analysis is always to identify the particular effect of interest, and for that you must answer the question: “power of what?” 3.1 Study design The study design we will use as an example throughout this tutorial comes from Julian Quandt’s blogpost (https://julianquandt.com/post/power-analysis-by-data-simulation-in-r-part-iv/). He describes this as: A new hypothetical research question focused on music preference. The overarching research goal will be to find out whether Rock or Pop music is better. Of course, we could just ask people what they prefer, but we want a more objective measure of what is Rock and Pop (people might have different ideas about the genres). Therefore, we will have participants listen to a bunch of different songs that are either from a Spotify “best-of-pop” or “best-of-rock” playlist and have them rate each song on an evaluation scale from 0-100 points. 3.2 Simple linear regression Canned routines exist to perform power analysis for some simple general linear models (GLMs), however, using simulation to calculate power for a GLM will serve as scaffolding to build intuition about the process of conducting power simulation more generally, which will be helpful when we later move to a more complex case using a mixed effects model. While the outcome in this example is bounded on the interval [0, 100], we will not concern ourselves with the issue of using a linear model with such an outcome. Likewise, we will make no effort to address the within-subject nature of the effect of interest in the GLM example. 3.2.1 Step 1: model specification The first step in simulation-based power analysis is to write down the regression model of interest, including all variables and parameters: \\[ \\textrm{liking}_i = \\beta_0 + \\beta_1 \\times \\textrm{genre}_i + \\epsilon_i \\] where the subscript \\(i\\) denotes an individual song, liking is an integer-based rating of a given song on the interval [0, 100], genre is a dummy coded binary variable indicating whether the song is classified as “rock” or “pop”, and we assume \\(\\epsilon_{i} \\sim \\mathcal{N}(0, \\sigma)\\). The parameter of interest is \\(\\beta_1\\) - the average difference in the rating of songs between the two genres. Table 3.1 lists all of the variables and parameters in the model. Table 3.1: Variables in the data-generating model and associated code-based names. model code description \\(\\textrm{liking}_i\\) \\(\\texttt{liking_i}\\) rating of song \\(i\\) on the interval [0, 100] \\(\\textrm{genre}_i\\) \\(\\texttt{genre_i}\\) genre of song \\(i\\) (0=‘pop’, 1=‘rock’) \\(\\beta_0\\) \\(\\texttt{beta_0}\\) intercept; mean of liking rating for ‘pop’ genre \\(\\beta_1\\) \\(\\texttt{beta_1}\\) ‘slope’; mean difference btw ‘pop’ and ‘rock’ song ratings \\(\\sigma\\) \\(\\texttt{sigma}\\) standard deviation of residuals \\(e_{i}\\) \\(\\texttt{e_i}\\) residual for song \\(i\\) 3.2.2 Step 2: Variable composition Once we have the model equation, we need to specify the details of the explanatory variables. In our model, we only have a single binary predictor, so the only decision to make is which coding scheme to use: dummy coding or zero sum coding. Here, we chose dummy coding, since our primary interest is in the difference between the “rock” and “pop” genres. In many other situations, we might include variables such as age and sex in the model. In which case we would need to determine reasonable settings for the range of age and the proportion of females to males. For example, the range of age might encompass the full possible range of human longevity (e.g., 0 to 120 years) or could be more focused on non-retired adults (e.g., 18 to 65 years). The proportion of females to males could theoretically vary anywhere in the interval (0, 1), but practically is rarely outside of the interval [0.45, 0.55]. 3.2.3 Step 3: Parameter composition Finally, we need to establish the data-generating parameters in your model. You may draw on your own, or your colleague’s, substantive expertise about the phenomenom you’re studying to determine what paramater values are plausible. Or, you might look to the literature for studies that examined similar effects. Table 3.2 lists parameter values we will use as a starting point. Later, we will try alternative values and compare power for each. Table 3.2: Settings for all data-generating parameters. code value description \\(\\texttt{beta_0}\\) 65 intercept; i.e., mean of liking rating for ‘pop’ genre \\(\\texttt{beta_1}\\) 15 slope; i.e, mean difference btw ‘pop’ and ‘rock’ song ratings \\(\\texttt{sigma}\\) 5 residual (error) sd 3.3 Mixed effects model Our mixed effects model example will follow the same steps as the simple linear regression, but this time incorporate some model machinery to account for by-subject clustering in the data. 3.3.1 Step 1: model specification Once again, we first write down the regression model of interest, including all variables and parameters: \\[ \\textrm{liking}_{ij} = \\beta_0 + U_{0j} + (\\beta_1 + U_{1j}) \\times \\textrm{genre}_i + \\epsilon_{ij} \\] where the subscript \\(i\\) denotes an individual song and \\(j\\) a participant, liking is an integer-based rating of a given song on the interval [0, 100], genre is a dummy coded binary variable indicating whether the song is classified as “rock” or “pop”, and we assume \\(U_{0j} \\sim \\mathcal{N}(0, \\tau_0)\\), \\(U_{1j} \\sim \\mathcal{N}(0, \\tau_1)\\), \\(\\epsilon_{ij} \\sim \\mathcal{N}(0, \\sigma)\\). The parameter of interest is \\(\\beta_1\\) - the average (within-subject) difference in the rating of songs between the two genres. Table 3.3 lists all of the variables and parameters in the model. Table 3.3: Variables in the data-generating model and associated code-based names. model code description \\(\\textrm{liking}_{ij}\\) \\(\\texttt{liking_ij}\\) rating of song \\(i\\) for participant \\(j\\) on the interval [0, 100] \\(\\textrm{genre}_i\\) \\(\\texttt{genre_i}\\) genre of song \\(i\\) (0=‘pop’, 1=‘rock’) \\(\\beta_0\\) \\(\\texttt{beta_0}\\) intercept; mean of liking rating for ‘pop’ genre \\(\\beta_1\\) \\(\\texttt{beta_1}\\) slope; mean difference btw ‘pop’ and ‘rock’ song ratings \\(\\tau_0\\) \\(\\texttt{tau_0}\\) standard deviation of by-subject random intercepts \\(\\tau_1\\) \\(\\texttt{tau_1}\\) standard deviation of by-subject random slopes \\(\\rho\\) \\(\\texttt{rho}\\) correlation between by-subject random intercepts and slopes \\(\\sigma\\) \\(\\texttt{sigma}\\) standard deviation of residuals \\(U_{0j}\\) \\(\\texttt{U_0j}\\) random intercept for subject \\(j\\) \\(U_{1j}\\) \\(\\texttt{U_1j}\\) random slope for subject \\(j\\) \\(e_{ij}\\) \\(\\texttt{e_ij}\\) residual of song \\(i\\) for participant \\(j\\) 3.3.2 Step 2: Variable composition We also need to think about the explanatory variables in our model. Since we only have a single binary predictor, we just need to decide which coding scheme to use: dummy coding or zero sum coding. Here, we chose dummy coding, since our primary interest is in the difference between the “rock” and “pop” genres. 3.3.3 Step 3: Parameter composition Finally, we need to establish the data-generating parameters in your model. As before, you may determine what paramater values are plausible by drawing on substantive expertise about the phenomenom you’re studying or by referencing the literature for studies that report similar effects. Table 3.4 lists parameter values we will use as a starting point. Later, we will try alternative values and compare power for each. Table 3.4: Settings for all data-generating parameters. code value description \\(\\texttt{beta_0}\\) 65 intercept; i.e., mean of liking rating for ‘pop’ genre \\(\\texttt{beta_1}\\) 15 slope; i.e, mean difference btw ‘pop’ and ‘rock’ song ratings \\(\\texttt{tau_0}\\) 7 by-subject random intercept sd \\(\\texttt{tau_1}\\) 3 by-subject random slope sd \\(\\texttt{rho}\\) 0.2 correlation between intercept and slope \\(\\texttt{sigma}\\) 5 residual (error) sd "],["r.html", "4 R 4.1 Simple linear regression 4.2 Mixed effects model", " 4 R 4.1 Simple linear regression 4.1.1 Setup The main library we will use is stats and comes bundled with base R. However, we also need to install a few additional libraries onto our machine and then load them into our search path. # install.packages(&quot;pacman&quot;) pacman::p_load( lme4, # model specification / estimation lmtest, afex, # anova and deriving p-values from lmer broom.mixed, # extracting tidy data from model fits tidyverse, # data wrangling and visualisation gt # nice tables ) We will also set the pseudo-random number generator seed to 02138 to make the stochastic components of our simulations reproducible. set.seed(02138) 4.1.2 Steps 4-5: Simulate and automate Next, let’s write a function that creates datasets under the alternative hypothesis, fits the models, and uses a likelihood-ratio test to calculate power. sample_n &lt;- c(400, 500, 600, 700) interact_coef &lt;- c(0.2, 0.25, 0.3, 0.35, 0.4) repeats &lt;- 1:1000 power_list &lt;- data.frame(sample_n=double(), interact_coef=double(), power=double() )[-1, ] for (s in sample_n) { for (i in interact_coef){ results &lt;- c() for (r in repeats){ age &lt;- ceiling(runif(s, 18, 65)) female &lt;- rbinom(s, 1, 0.5) interact &lt;- age * female e &lt;- rnorm(s, 0, 20) sbp &lt;- 110 + 0.5*age + (-20)*female + i*interact + e dataset &lt;- data.frame(sbp, age, female, interact) full_model &lt;- lm(sbp ~ age + female + interact, data=dataset) reduced_model &lt;- lm(sbp ~ age + female, data=dataset) prob &lt;- lrtest(full_model, reduced_model)$Pr[2] reject &lt;- ifelse((prob&lt;=0.05), 1, 0) results &lt;- rbind(results, reject) } power_list &lt;- rbind(power_list, data.frame(sample_n=s, interact_coef=i, power=mean(results) ) ) } } 4.1.3 Step 6: Summarize Here’s the table from the simulation. power_list |&gt; gt() |&gt; tab_header(title=&quot;Power values for GLM&quot;) |&gt; data_color( columns=power, colors=scales::col_numeric( palette=c(&quot;red&quot;, &quot;green&quot;), domain=c(0, 1) ) ) Here’s the graph from the simulation. power_list |&gt; mutate(sample_n = factor(sample_n)) |&gt; ggplot(aes(x=interact_coef, y=power, group=sample_n, color=sample_n)) + geom_line() + geom_point(size=4) + ylim(0, 1) + theme_bw() 4.2 Mixed effects model For the mixed effects model example, we will continue to use the same R libraries and pseudo-random number generator seed as previously. 4.2.1 Step 4-5: Simulate &amp; automate Next, let’s write a function that creates datasets under the alternative hypothesis, fits the mixed effects models, tests the null hypothesis of interest, and uses a for loop to run many iterations of the function. sample_n &lt;- c(100, 200, 300, 400, 500) obs_n &lt;- c(3, 5) reps_n &lt;- 1:100 power_list_mixed &lt;- data.frame(obs=integer(), sample=integer(), power=double() ) for (s in sample_n){ for (o in obs_n){ results &lt;- c() for (r in reps_n){ data.frame( child = factor(1:s), female = rbinom(s, 1, 0.5), u_0i = rnorm(s, 0, 0.8), u_1i = rnorm(s, 0, 1.7) ) -&gt; data_set data_set_expand &lt;- data_set[rep(seq(nrow(data_set)), o), 1:4] age &lt;- c() for (obser in seq(0, (o-1)*0.5, 0.5)){ age &lt;- c(age, rep(obser, s)) } data_set_expand |&gt; mutate(age = age, e_ij = rnorm(s*o, 0, 1.35), interact = age * female, weight = 5.35 + 2.1*age + (-0.35)*female + (-0.55)*interact + u_0i + age*u_1i + e_ij ) -&gt; data_set_expand full_model &lt;- lmer(weight ~ age + female + interact + (age || child), data=data_set_expand) reduced_model &lt;- lmer(weight ~ age + female + (age || child), data=data_set_expand) prob &lt;- lrtest(full_model, reduced_model)$Pr[2] reject &lt;- ifelse((prob&lt;=0.05), 1, 0) results &lt;- rbind(results, reject) } power_list_mixed &lt;- rbind(power_list_mixed, data.frame(obs=o, sample=s, power=mean(results) ) ) } } 4.2.2 Step 6: Summarize The table for the mixed effects model. power_list_mixed |&gt; gt() |&gt; tab_header(title=&quot;Power values for mixed effects model&quot;) |&gt; data_color( columns=power, colors=scales::col_numeric( palette=c(&quot;red&quot;, &quot;green&quot;), domain=c(0, 1) ) ) The graph of the simulation result for mixed effects model. power_list_mixed |&gt; mutate(obs = factor(obs)) |&gt; ggplot(aes(x=sample, y=power, group=obs, color=obs)) + geom_line() + geom_point(size=4) + ylim(0, 1) + theme_bw() "],["python.html", "5 Python 5.1 Simple linear regression 5.2 Mixed effects model", " 5 Python 5.1 Simple linear regression 5.1.1 Setup First, let’s import the libraries used for simulation based power analysis in Python. import random import numpy as np import pandas as pd from sklearn.linear_model import LinearRegression import statsmodels.api as sm import scipy import matplotlib.pyplot as plt We will also set the pseudo-random number generator seed to 02138 to make the stochastic components of our simulations reproducible. np.random.seed(02138) 5.1.2 Step 4: Simulate Next, we create a simulated dataset based on our assumptions about the model under the alternative hypothesis, and fit the model. def generate_dataset(sample_size, interact_coef): data_set = [] for i in range(sample_size): _id = i age = np.random.randint(18,66) female = np.random.choice([0, 1]) interact = age * female e = np.random.normal(0, 20) sbp = 110 + 0.5*age + (-20)*female + interact_coef*interact + e data_set.append([_id, age, female, interact, e, sbp]) data_set = pd.DataFrame(data_set) data_set.columns = [&quot;_id&quot;, &quot;age&quot;, &quot;female&quot;, &quot;interact&quot;, &#39;e&#39;, &quot;sbp&quot;] return data_set 5.1.3 Step 5: Automate Next, let’s write a function that creates datasets under the alternative hypothesis, fits the models, and uses a likelihood-ratio test to calculate power. def cal_power(sample_size, interact_coef, simiu_cnt, alpha): power_list = [] for i in range(simiu_cnt): dataset = generate_dataset(sample_size, interact_coef) y1 = dataset[&#39;sbp&#39;] x1 = dataset[[&#39;age&#39;, &#39;female&#39;, &#39;interact&#39;]] x1 = sm.add_constant(x1) full_model = sm.OLS(y1, x1).fit() full_ll = full_model.llf y2 = dataset[&#39;sbp&#39;] x2 = dataset[[&#39;age&#39;, &#39;female&#39;]] x2 = sm.add_constant(x2) reduced_model = sm.OLS(y2, x2).fit() reduced_ll = reduced_model.llf LR_statistic = -2*(reduced_ll-full_ll) power = scipy.stats.chi2.sf(LR_statistic, 1) if power&lt;=alpha: power_list.append(1) else: power_list.append(0) mean_power = sum(power_list)/len(power_list) return [sample_size, interact_coef, mean_power] result = [] for i in range(400, 800, 100): for j in [0.2, 0.25, 0.3, 0.35, 0.4]: result.append(cal_power(sample_size = i, interact_coef = j, simiu_cnt = 1000, alpha = 0.05)) result = pd.DataFrame(result) result.columns = [&#39;N&#39;, &#39;interact_coef&#39;, &#39;Power&#39;] result 5.1.4 Step 6: Summarize In this part, we export the results of the simulations which include two parts: a table and a graph showing the results from the simulations. It should be noted that the graph from Python simulation is a little bit different from that in Stata, and this is mainly caused by different simulation process within Stata and Python. N interact_coef Power 0 400 0.20 0.320 1 400 0.25 0.413 2 400 0.30 0.557 3 400 0.35 0.664 4 400 0.40 0.798 5 500 0.20 0.328 6 500 0.25 0.513 7 500 0.30 0.636 8 500 0.35 0.788 9 500 0.40 0.869 10 600 0.20 0.406 11 600 0.25 0.569 12 600 0.30 0.714 13 600 0.35 0.829 14 600 0.40 0.926 15 700 0.20 0.447 16 700 0.25 0.601 17 700 0.30 0.776 18 700 0.35 0.887 19 700 0.40 0.955 n_list = result[&#39;N&#39;].unique() color_list = [&#39;darkblue&#39;, &#39;firebrick&#39;, &#39;darkgreen&#39;, &#39;orange&#39;] plt.figure(figsize=(15,6)) for i in range(len(n_list)): n = n_list[i] c = color_list[i] plt.plot(result[result[&#39;N&#39;]==n][&#39;interact_coef&#39;], result[result[&#39;N&#39;]==n][&#39;Power&#39;], &#39;o-&#39;, color = c) plt.grid() plt.xticks([0.2, 0.25, 0.3, 0.35, 0.4], fontsize = 12) plt.yticks([0.2, 0.4, 0.6, 0.8, 1], fontsize = 12) plt.xlabel(&#39;interact&#39;, fontsize = 15) plt.ylabel(&#39;Power&#39;, fontsize = 15) plt.legend(result[&#39;N&#39;].unique(), fontsize = 12) plt.title(&#39;Estimate Power: Two-sided Test&#39;, fontsize = 18) plt.show() 5.2 Mixed effects model For the mixed effects model example, we will continue to use the same Python libraries and pseudo-random number generator seed as previously. 5.2.1 Step 4: Simulate Next, we create a simulated dataset based on our assumptions about the model under the alternative hypothesis, and fit the model. We will simulate 5 observations at 4-month increments for 200 children. def generate_dataset(sample_size, obser_cnt): data_set = [] for i in range(sample_size): child_id = i female_origin = np.random.choice([0, 1]) u_0i_origin = np.random.normal(0, 0.25) u_1i_origin = np.random.normal(0, 0.60) for j in range(obser_cnt): child = child_id female = female_origin age = 0.5*j u_0i = u_0i_origin u_1i = u_1i_origin interaction = age * female e_ij = np.random.normal(0, 1.2) weight = 5.35 + 3.6*age + (-0.5)*female + (-0.25)*interaction + u_0i + age*u_1i + e_ij data_set.append([child, female, age, u_0i, u_1i, interaction, e_ij, weight]) data_set = pd.DataFrame(data_set) data_set.columns = [&quot;child_id&quot;, &quot;female&quot;, &quot;age&quot;, &quot;u_0i&quot;, &quot;u_li&quot;, &quot;interaction&quot;, &quot;e_ij&quot;, &quot;weight&quot;] return data_set 5.2.2 Step 5: Automate Next, let’s write a function that creates datasets under the alternative hypothesis, fits the mixed effects models, tests the null hypothesis of interest, and uses a for loop to run many iterations of the function. def cal_power(sample_size, obser_cnt, simiu_cnt, alpha): power_list = [] for i in range(simiu_cnt): dataset = generate_dataset(sample_size, obser_cnt) y1 = dataset[&#39;weight&#39;] x1 = dataset[[&#39;female&#39;, &#39;age&#39;, &#39;interaction&#39;]] x1 = sm.add_constant(x1) full_model = sm.OLS(y1, x1).fit() full_ll = full_model.llf y2 = dataset[&#39;weight&#39;] x2 = dataset[[&#39;female&#39;, &#39;age&#39;]] x2 = sm.add_constant(x2) reduced_model = sm.OLS(y2, x2).fit() reduced_ll = reduced_model.llf LR_statistic = -2*(reduced_ll-full_ll) power = scipy.stats.chi2.sf(LR_statistic, 1) if power&lt;=alpha: power_list.append(1) else: power_list.append(0) mean_power = sum(power_list)/len(power_list) return [obser_cnt, sample_size, mean_power] result = [] for i in range(100, 600, 100): for j in range(5, 7): result.append(cal_power(sample_size = i, obser_cnt = j, simiu_cnt = 1000, alpha = 0.05)) result = pd.DataFrame(result) result.columns = [&#39;n1&#39;, &#39;N&#39;, &#39;Power&#39;] result 5.2.3 Step 6: Summarize The last procedure is to export the results which contain a table and a graph. n1 N Power 0 5 100 0.290 1 6 100 0.398 2 5 200 0.491 3 6 200 0.632 4 5 300 0.655 5 6 300 0.798 6 5 400 0.779 7 6 400 0.917 8 5 500 0.857 9 6 500 0.940 n1_list = result[&#39;n1&#39;].unique() color_list = [&#39;darkblue&#39;, &#39;firebrick&#39;] plt.figure(figsize=(15,6)) for i in range(len(n1_list)): n = n1_list[i] c = color_list[i] plt.plot(result[result[&#39;n1&#39;]==n][&#39;N&#39;], result[result[&#39;n1&#39;]==n][&#39;Power&#39;], &#39;-o&#39;, color = c) plt.grid() plt.xticks([100, 200, 300, 400, 500], fontsize = 12) plt.yticks([0.2, 0.4, 0.6, 0.8, 1], fontsize = 12) plt.xlabel(&#39;Level 2 Sample Size&#39;, fontsize = 15) plt.ylabel(&#39;Power&#39;, fontsize = 15) plt.legend(result[&#39;n1&#39;].unique(), fontsize = 12) plt.title(&#39;Power: Two-sided Test&#39;, fontsize = 18) plt.show() "],["stata.html", "6 Stata 6.1 Simple linear regression 6.2 Mixed effects model", " 6 Stata 6.1 Simple linear regression 6.1.1 Setup We will also set the pseudo-random number generator seed to 02138 to make the stochastic components of our simulations reproducible. set seed 02138 6.1.2 Step 4: Simulate Next, we create a simulated dataset based on our assumptions about the model under the alternative hypothesis, and fit the model. clear set obs 400 generate age = runiformint(18,65) generate female = rbinomial(1,0.5) generate interact = age*female generate e = rnormal(0,20) generate sbp = 110 + 0.5*age + (-20)*female + 0.35*interact + e We can then test the null hypothesis that the interaction term equals zero using a likelihood-ratio test. regress sbp age i.female c.age#i.female estimates store full regress sbp age i.female estimates store reduced Likelihood-ratio test LR chi2(1) = 13.38 (Assumption: reduced nested in full) Prob &gt; chi2 = 0.0003 The test yields a p-value of 0.0003. return list scalars: r(p) = .0002540647000293 r(chi2) = 13.38189649447986 r(df) = 1 local reject = (r(p)&lt;0.05) 6.1.3 Step 5: Automate Next, let’s write a program that creates datasets under the alternative hypothesis, fits the models, and uses the simulate command to test the program. capture program drop simregress program simregress, rclass version 16 // DEFINE THE INPUT PARAMETERS AND THEIR DEFAULT VALUES syntax, n(integer) /// Sample size [ alpha(real 0.05) /// Alpha level intercept(real 110) /// Intercept parameter age(real 0.5) /// Age parameter female(real -20) /// Female parameter interact(real 0.35) /// Interaction parameter esd(real 20) ] // Standard deviation of the error quietly { // GENERATE THE RANDOM DATA clear set obs `n&#39; generate age = runiformint(18,65) generate female = rbinomial(1,0.5) generate interact = age*female generate e = rnormal(0,`esd&#39;) generate sbp = `intercept&#39; + `age&#39;*age + `female&#39;*female + /// `interact&#39;*interact + e // TEST THE NULL HYPOTHESIS regress sbp age i.female c.age#i.female estimates store full regress sbp age i.female estimates store reduced lrtest full reduced } // RETURN RESULTS return scalar reject = (r(p)&lt;`alpha&#39;) end Below, we use simulate to run simregress 200 times and summarize the variable reject. The results indicate that we would have 74% power to detect an interaction parameter of 0.35 given a sample of 400 participants and the other assumptions about the model. simulate reject=r(reject), reps(200) seed(12345): /// simttest, n(200) m0(70) ma(75) sd(15) alpha(0.05) Simulations (200) ----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5 .................................................. 50 .................................................. 100 .................................................. 150 .................................................. 200 summarize reject Variable | Obs Mean Std. dev. Min Max -------------+--------------------------------------------------------- reject | 200 .735 .4424407 0 1 Next, let’s write a program called power\\_cmd\\_simregress so that we can integrate simregress into Stata’s power command. capture program drop power_cmd_simregress program power_cmd_simregress, rclass version 17 // DEFINE THE INPUT PARAMETERS AND THEIR DEFAULT VALUES syntax, n(integer) /// Sample size [ alpha(real 0.05) /// Alpha level intercept(real 110) /// Intercept parameter age(real 0.5) /// Age parameter female(real -20) /// Female parameter interact(real 0.35) /// Interaction parameter esd(real 20) /// Standard deviation of the error reps(integer 100)] // Number of repetitions // GENERATE THE RANDOM DATA AND TEST THE NULL HYPOTHESIS quietly { simulate reject=r(reject), reps(`reps&#39;): /// simregress, n(`n&#39;) age(`age&#39;) female(`female&#39;) /// interact(`interact&#39;) esd(`esd&#39;) alpha(`alpha&#39;) summarize reject } // RETURN RESULTS return scalar power = r(mean) return scalar N = `n&#39; return scalar alpha = `alpha&#39; return scalar intercept = `intercept&#39; return scalar age = `age&#39; return scalar female = `female&#39; return scalar interact = `interact&#39; return scalar esd = `esd&#39; end Finally, run power simregress for a range of input parameter values, including the parameters listed in double quotes. To do this, we first need to create a program called power\\_cmd\\_simregress\\_init. capture program drop power_cmd_simregress_init program power_cmd_simregress_init, sclass sreturn local pss_colnames &quot;intercept age female interact esd&quot; sreturn local pss_numopts &quot;intercept age female interact esd&quot; end 6.1.4 Step 6: Summarize Now, we’re ready to use power simregress! The output below shows the simulated power when the interaction parameter equals 0.2 to 0.4 in increments of 0.05 for samples of size 400, 500, 600, and 700. power simregress, n(400(100)700) intercept(110) /// age(0.5) female(-20) interact(0.2(0.05)0.4) /// reps(1000) table graph(xdimension(interact) /// legend(rows(1))) Estimated power Two-sided test +--------------------------------------------------------------------+ | alpha power N intercept age female interact esd | |--------------------------------------------------------------------| | .05 .3 400 110 .5 -20 .2 20 | | .05 .421 400 110 .5 -20 .25 20 | | .05 .546 400 110 .5 -20 .3 20 | | .05 .685 400 110 .5 -20 .35 20 | | .05 .767 400 110 .5 -20 .4 20 | | .05 .34 500 110 .5 -20 .2 20 | | .05 .509 500 110 .5 -20 .25 20 | | .05 .63 500 110 .5 -20 .3 20 | | .05 .767 500 110 .5 -20 .35 20 | | .05 .872 500 110 .5 -20 .4 20 | | .05 .412 600 110 .5 -20 .2 20 | | .05 .556 600 110 .5 -20 .25 20 | | .05 .712 600 110 .5 -20 .3 20 | | .05 .829 600 110 .5 -20 .35 20 | | .05 .886 600 110 .5 -20 .4 20 | | .05 .471 700 110 .5 -20 .2 20 | | .05 .634 700 110 .5 -20 .25 20 | | .05 .771 700 110 .5 -20 .3 20 | | .05 .908 700 110 .5 -20 .35 20 | | .05 .957 700 110 .5 -20 .4 20 | +--------------------------------------------------------------------+ 6.2 Mixed effects model 6.2.1 Setup Again, we set the seed to 02138. set seed 02138 6.2.2 Step 4: Simulate Next, we create a simulated dataset based on our assumptions about the model under the alternative hypothesis, and fit the model. We will simulate 5 observations at 4-month increments for 200 children. clear set obs 200 generate child = _n generate female = rbinomial(1,0.5) generate u_0i = rnormal(0,0.25) generate u_1i = rnormal(0,0.60) expand 5 bysort child: generate age = (_n-1)*0.5 generate interaction = age*female generate e_ij = rnormal(0,1.2) generate weight = 5.35 + 3.6*age + (-0.5)*female + (-0.25)*interaction /// + u_0i + age*u_1i + e_ij Our dataset includes the random deviations that we would not observe in a real dataset. We can then use mixed to fit a model to our simulated data. mixed weight age i.female c.age#i.female || child: age , stddev nolog noheader estimates store full mixed weight age i.female || child: age , stddev nolog noheader estimates store reduced lrtest full reduced We can then test the null hypothesis that the interaction term equals zero using a likelihood-ratio test. lrtest full reduced Likelihood-ratio test LR chi2(1) = 8.23 (Assumption: reduced nested in full) Prob &gt; chi2 = 0.0041 The \\(p\\)-value for our test is 0.0041, so we would reject the null hypothesis that the interaction term equals zero. 6.2.3 Step 5: Automate Next, let’s write a program that creates datasets under the alternative hypothesis, fits the mixed effects models, tests the null hypothesis of interest, and uses the simulate command to run many iterations of the program. capture program drop simmixed program simmixed, rclass version 16 // PARSE INPUT syntax, n1(integer) /// n(integer) /// [ alpha(real 0.05) /// intercept(real 5.35) /// age(real 3.6) /// female(real -0.5) /// interact(real -0.25) /// u0i(real 0.25) /// u1i(real 0.60) /// eij(real 1.2) ] // COMPUTE POWER quietly { drop _all set obs `n&#39; generate child = _n generate female = rbinomial(1,0.5) generate u_0i = rnormal(0,`u0i&#39;) generate u_1i = rnormal(0,`u1i&#39;) expand `n1&#39; bysort child: generate age = (_n-1)*0.5 generate interaction = age*female generate e_ij = rnormal(0,`eij&#39;) generate weight = `intercept&#39; + `age&#39;*age + `female&#39;*female + /// `interact&#39;*interaction + u_0i + age*u_1i + e_ij mixed weight age i.female c.age#i.female || child: age, iter(200) local conv1 = e(converged) estimates store full mixed weight age i.female || child: age, iter(200) local conv2 = e(converged) estimates store reduced lrtest full reduced local reject = cond(`conv1&#39; + `conv2&#39;==2, (r(p)&lt;`alpha&#39;), .) } // RETURN RESULTS return scalar reject = `reject&#39; return scalar conv = `conv1&#39;+`conv2&#39; end We then use simulate to run simmixed 10 times using the default parameter values for 5 observations on each of 200 children. simulate reject=r(reject) converged=r(conv), reps(10) seed(12345): simmixed, n1(5) n(200) command: simmixed, n1(5) n(200) reject: r(reject) converged: r(conv) Simulations (10) ----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5 simulate saved the results of the hypothesis tests to a variable named reject. The mean of reject is our estimate of the power to test the null hypothesis that the age×sex interaction term equals zero, assuming that the weight of 200 children is measured 5 times. We could stop with our quick simulation if we were interested only in a specific set of assumptions. But it’s easy to write an additional program named power\\_cmd\\_simmixed that will allow us to use Stata’s power command to create tables and graphs for a range of sample sizes. capture program drop power_cmd_simmixed program power_cmd_simmixed, rclass version 16 // PARSE INPUT syntax, n1(integer) /// n(integer) /// [ alpha(real 0.05) /// intercept(real 5.35) /// age(real 3.6) /// female(real -0.5) /// interact(real -0.25) /// u0i(real 0.25) /// u1i(real 0.60) /// eij(real 1.2) /// reps(integer 1000) ] // COMPUTE POWER quietly { simulate reject=r(reject), reps(`reps&#39;): /// simmixed, n1(`n1&#39;) n(`n&#39;) alpha(`alpha&#39;) intercept(`intercept&#39;) /// age(`age&#39;) female(`female&#39;) interact(`interact&#39;) /// u0i(`u0i&#39;) u1i(`u1i&#39;) eij(`eij&#39;) summarize reject } // RETURN RESULTS return scalar power = r(mean) return scalar n1 = `n1&#39; return scalar N = `n&#39; return scalar alpha = `alpha&#39; return scalar intercept = `intercept&#39; return scalar age = `age&#39; return scalar female = `female&#39; return scalar interact = `interact&#39; return scalar u0i = `u0i&#39; return scalar u1i = `u1i&#39; return scalar eij = `eij&#39; end It’s also easy to write a program named power\\_cmd\\_simmixed\\_init that will allow us to simulate power for a range of values for the parameters in our model. capture program drop power_cmd_simmixed_init program power_cmd_simmixed_init, sclass version 16 sreturn clear // ADD COLUMNS TO THE OUTPUT TABLE sreturn local pss_colnames &quot;n1 intercept age female interact u0i u1i eij&quot; // ALLOW NUMLISTS FOR ALL PARAMETERS sreturn local pss_numopts &quot;n1 intercept age female interact u0i u1i eij&quot; end 6.2.4 Step 6: Summarize Now, we can use power simmixed to simulate power for a variety of assumptions. The example below simulates power for a range of sample sizes at both levels 1 and 2. Level 2 sample sizes range from 100 to 500 children in increments of 100. At level 1, we consider 5 and 6 observations per child. power simmixed, n1(5 6) n(100(100)500) reps(1000) table(n1 N power) graph(ydimension(power) xdimension(N) plotdimension(n1) xtitle(Level 2 Sample Size) legend(title(Level 1 Sample Size))) xxxxxxxxxxxxxxxxxxxxxxxxxxx Estimated power Two-sided test +-------------------------+ | n1 N power | |-------------------------| | 5 100 .2629 | | 6 100 .313 | | 5 200 .397 | | 6 200 .569 | | 5 300 .621 | | 6 300 .735 | | 5 400 .734 | | 6 400 .855 | | 5 500 .828 | | 6 500 .917 | +-------------------------+ "],["software-comparison.html", "7 Software Comparison", " 7 Software Comparison "],["resources.html", "Resources", " Resources We would like to acknowledge some excellent online and peer-reviewed material about power simulation and mixed effects models, which we have borrowed from liberally in the tutorial. These resouces represent an excellent next step in your exploration of simulation-based power analysis. R DeBruine &amp; Barr (2021) paper on using simulation to understand mixed effects models: https://journals.sagepub.com/doi/epdf/10.1177/2515245920965119 Julian Quandt’s 4-part blog series on power analysis via simulation: https://julianquandt.com/post/power-analysis-by-data-simulation-in-r-part-i/ https://julianquandt.com/post/power-analysis-by-data-simulation-in-r-part-ii/ https://julianquandt.com/post/power-analysis-by-data-simulation-in-r-part-iii/ https://julianquandt.com/post/power-analysis-by-data-simulation-in-r-part-iv/ Stata Chuck Huber’s 4-part blog series on power analysis via simulation: https://blog.stata.com/2019/01/10/calculating-power-using-monte-carlo-simulations-part-1-the-basics/ https://blog.stata.com/2019/01/29/calculating-power-using-monte-carlo-simulations-part-2-running-your-simulation-using-power/ https://blog.stata.com/2019/08/13/calculating-power-using-monte-carlo-simulations-part-3-linear-and-logistic-regression/ https://blog.stata.com/2019/08/20/calculating-power-using-monte-carlo-simulations-part-4-multilevel-longitudinal-models/ "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
